[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I’m Francisco Mussari, blogging from Caracas about data, ai, cloud computing, engineering and social sciences."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "datamatica",
    "section": "",
    "text": "computer-vision\n\n\ndeeplearning\n\n\nazure\n\n\ncustom-vision\n\n\nobject-detection\n\n\n\n\n\n\n\n\n\n\n\nOct 15, 2022\n\n\nFrancisco Mussari\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ncomputer-vision\n\n\ndeeplearning\n\n\nazure\n\n\ncustom-vision\n\n\nobject-detection\n\n\n\n\n\n\n\n\n\n\n\nOct 8, 2022\n\n\nFrancisco Mussari\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nOct 3, 2022\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nSep 30, 2022\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_1.html",
    "href": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_1.html",
    "title": "Telecom Equipment Detection with Azure Custom Vision (Free) - Part 1",
    "section": "",
    "text": "Part 1. Create the service and upload the pictures"
  },
  {
    "objectID": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_1.html#introduction",
    "href": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_1.html#introduction",
    "title": "Telecom Equipment Detection with Azure Custom Vision (Free) - Part 1",
    "section": "Introduction",
    "text": "Introduction\nIn this series of posts we are going to follow along the process and code required to train an object detection model using Azure Custom Vision (in its free tier).\nWe are going to use real world pictures compiled from work I have done over the years in Venezuela. In this kind of supervised learning problem we need tagged images. So we will use Smart Labeler to do that.\nAfter the model is published in Azure service, we can use the API to build and share a demo with Gradio and Huggingface.\nHere is the one that is already published for you to try:\nTelecom-Object-Detection\n\nThe model will be trained to detect the following objects:\n\nGrid Antenna\nPanel antenna\nRadome antenna\nRRU\nShroud antenna\nSolid antenna\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrid\n\n\nPanel\n\n\nRadome\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRRU\n\n\nShroud\n\n\nSolid"
  },
  {
    "objectID": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_1.html#tutorial-parts",
    "href": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_1.html#tutorial-parts",
    "title": "Telecom Equipment Detection with Azure Custom Vision (Free) - Part 1",
    "section": "Tutorial Parts",
    "text": "Tutorial Parts\n\nPart 1 will cover:\n\nCreating a free Azure Custom Vision Service.\nUploading the images to the service.\n\nPart 2 will cover:\n\nAnalyzing what happens to the images after uploading.\nHow to label the images using Smart Labeler\nTraining and publishing the model.\n\nPart 3 will cover:\n\nCreate a Huggingface Gradio Demo."
  },
  {
    "objectID": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_1.html#references",
    "href": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_1.html#references",
    "title": "Telecom Equipment Detection with Azure Custom Vision (Free) - Part 1",
    "section": "References",
    "text": "References\n\nMicrosoft Learn Excersice: Detect Objects in Images with Custom Vision\nCustom Vision Documentation: Quickstart: Create an object detection project with the Custom Vision client library\nREST API Endpoint: Custom Vision REST API reference - Azure Cognitive Services\nAPIs Documentation: Custom_Vision_Training_3.3\nAzure SDK for Python: Custom Vision Client Library\nSource Code: Azure/azure-sdk-for-python"
  },
  {
    "objectID": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_1.html#part-1.1.-create-a-custom-vision-service",
    "href": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_1.html#part-1.1.-create-a-custom-vision-service",
    "title": "Telecom Equipment Detection with Azure Custom Vision (Free) - Part 1",
    "section": "Part 1.1. Create a Custom Vision Service",
    "text": "Part 1.1. Create a Custom Vision Service\nI’m not going to get into the details of creating the service. And the reason is that there is a detailed tutorial covering not just that, but also the code for uploading and training a simple model. I encourage you to try it first:\nDetect Objects in Images with Custom Vision\n\nFor this tutorial I created a Custom Vision with the following settings:\n\nCustom Vision service:\n\nResource: ai102cvision\nResource Kind: Custom Vision Training\n\nProject:\n\nName: Telecom Equipment Detection\nDescription: Detect different types of antennas\nResource: ai102cvision [F0]\nProject Types: Object Detection\nDomains: General"
  },
  {
    "objectID": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_1.html#part-1.2.-upload-the-images",
    "href": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_1.html#part-1.2.-upload-the-images",
    "title": "Telecom Equipment Detection with Azure Custom Vision (Free) - Part 1",
    "section": "Part 1.2. Upload the images",
    "text": "Part 1.2. Upload the images\n\nEnvironment variables\nUpdate the configuration variables in the .env file that contains:\nTrainingEndpoint=YOUR_TRAINING_ENDPOINT\nTrainingKey=YOUR_TRAINING_KEY\nProjectID=YOUR_PROJECT_ID\n\n\n\n\n\n\nNote\n\n\n\nIn order to protect my credentials, I’m going to store .env file in a creds folder that isn’t being pushed to github.\n\n\n\nDOTENV_PATH = './.env'\n\n\n\nInstall and import libraries\nWe need to install Custom Vision’s Python SDK and python-dotenv:\n! pip install azure-cognitiveservices-vision-customvision==3.1.0\n! pip install python-dotenv\n\nfrom azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\nfrom azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry, Region\nfrom msrest.authentication import ApiKeyCredentials\nimport time\nimport json\nimport os\n\nimport pandas as pd\nfrom dotenv import load_dotenv\nfrom pathlib import Path\n\nfrom PIL import Image, ImageOps\nfrom PIL import UnidentifiedImageError\n\nimport matplotlib.pyplot as plt\n\n\n\nCredentials and services\n\nApiKeyCredentials\nCustomVisionTrainingClient\nCustomVisionTrainingClient.get_project()\n\n\nload_dotenv(DOTENV_PATH)\ntraining_endpoint = os.getenv('TrainingEndpoint')\ntraining_key = os.getenv('TrainingKey')\nproject_id = os.getenv('ProjectID')\n\ncredentials = ApiKeyCredentials(in_headers={\"Training-key\": training_key})\ntraining_client = CustomVisionTrainingClient(training_endpoint, credentials)\ncustom_vision_project = training_client.get_project(project_id)\n\n\n\nFunctions\n\n# Borrowed from fastai library\ndef verify_image(fn):\n    \"Confirm that `fn` can be opened\"\n    try:\n        im = Image.open(fn)\n        im.draft(im.mode, (32,32))\n        im.load()\n        return True\n    except: return False\n    #except PIL.UnidentifiedImageError:\n\nThe SDK / API allows to upload images in batches but I didn’t find a way to match the local image name with the id generated by the service. Then I opted to create a function that uploads the pictures one by one.\n\nImageFileCreateEntry\nCustomVisionTrainingClient.create_images_from_files()\n\n\ndef Upload_Images_1by1(pictures: list[Path]) -> list('dict'):\n    \"\"\"Upload the pictures from a list of paths,\n    one by one to keep track of the relation between\n    local image name and Azure image id.\n    And to track the ones that python fails opening\n    \"\"\"\n    print(\"Uploading images...\")\n\n    processed_ids = []\n    processed_status = []\n    picture_names = []\n\n    for pic_path in pictures:\n\n        if verify_image(pic_path):\n            with open(pic_path, mode=\"rb\") as image_data:\n                image_entry = ImageFileCreateEntry(\n                    name=pic_path.name, contents=image_data.read()\n                )\n            \n            # Upload the list of (1) images as a batch\n            upload_result = training_client.create_images_from_files(\n                custom_vision_project.id, \n                # Creates an ImageFileCreateBatch from a list of 1 ImageFileCreateEntry\n                ImageFileCreateBatch(images=[image_entry])\n            )\n            # Check for failure\n            if not upload_result.is_batch_successful:\n                pic_status = upload_result.images[0].status\n                pic_id = None\n            else:\n                pic_status = upload_result.images[0].status\n                pic_id = upload_result.images[0].image.id\n        else:\n            pic_status = \"ReadError\" # Equivalente to SDK `ErrorSource`\n            pic_id = None\n        \n        processed_status.append(pic_status)\n        processed_ids.append(pic_id)\n        picture_names.append(pic_path.name)\n        print(pic_path.name, \"//\", pic_id, \"//\", pic_status)\n    \n    return {\"image_name\": picture_names, \n            \"image_id\": processed_ids, \n            \"image_status\": processed_status}\n\n\n\nExplore pictures\n\npics_folder = Path('./train_images')\n\npictures = sorted(list(pics_folder.iterdir()))\n\nprint(f\"There are {len(pictures)} pictures\")\n\nThere are 203 pictures\n\n\n\nfig, axes = plt.subplots(3, 4, figsize=(16, 12))\n\ndef show_img(im, figsize=None, ax=None):\n    if not ax: fig, ax = plt.subplots(figsize=figsize)\n    ax.imshow(im)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    return ax\n\nfor i, ax in enumerate(axes.flat):\n    im = Image.open( pictures[i*10] )\n    ax = show_img(im, ax=ax)\n\n\n\n\nAs you can see the pictures are very varied. Different cameras, lighting conditions, focus, resolutions and sizes…\n\n\nUpload the pictures to Custom Vision Service\n\nuploaded_images_df = pd.DataFrame(columns=[\"image_name\", \"image_id\", \"image_status\"])\n\n\nupload_batch = Upload_Images_1by1(pictures)\n\n\nuploaded_images_df = pd.DataFrame(upload_batch)\nuploaded_images_df\n\n\n\n\n\n  \n    \n      \n      image_name\n      image_id\n      image_status\n    \n  \n  \n    \n      0\n      41.JPG\n      452a0b58-0dc5-41ff-83d1-8d1ae7bd5d1c\n      OK\n    \n    \n      1\n      CIMG0030.JPG\n      96b7774e-f5ad-4591-aa71-99ad5c71135e\n      OK\n    \n    \n      2\n      CIMG0031.JPG\n      3027bc7e-6e21-4b13-a7d7-bb7e08ce6824\n      OK\n    \n    \n      3\n      CIMG0056.JPG\n      1320ab2e-3405-4853-bd7e-b0ef0f915d4b\n      OK\n    \n    \n      4\n      CIMG0059.JPG\n      aa67eceb-3db0-4026-bf16-0842c006e6ac\n      OK\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      198\n      torre cerro el pavon 075.jpg\n      b6dd061a-a68d-4d91-a39f-711968445571\n      OK\n    \n    \n      199\n      torre cerro el pavon 080.jpg\n      d12264cf-3d7b-469c-9445-da8dce8dabef\n      OK\n    \n    \n      200\n      torre cerro el pavon 085.jpg\n      c6d587fe-5f3a-46ea-bc04-7ff54f10b4ae\n      OK\n    \n    \n      201\n      torre cerro el pavon 086.jpg\n      ea34cbad-8d50-4b5f-aed0-91d7fe40a754\n      OK\n    \n    \n      202\n      torre cerro el pavon 087.jpg\n      6e274dfc-411a-4bf3-9151-51b96f662248\n      OK\n    \n  \n\n203 rows × 3 columns\n\n\n\n\nprint(f\"{sum(uploaded_images_df.image_status != 'OK')} \n      images failed when uploading\")\n\n0 images failed uploading\n\n\nSave a csv:\n\nuploaded_images_df.to_csv('20221012_203_Images_Uploaded.csv', index=False)"
  },
  {
    "objectID": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_1.html#part-1.3.-explore-data-from-custom-vision-service",
    "href": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_1.html#part-1.3.-explore-data-from-custom-vision-service",
    "title": "Telecom Equipment Detection with Azure Custom Vision (Free) - Part 1",
    "section": "Part 1.3. Explore Data from Custom Vision Service",
    "text": "Part 1.3. Explore Data from Custom Vision Service\n\nGet id’s of uploaded images\n\nCustomVisionTrainingClient.get_images()\n\n\ntrain_images = training_client.get_images(\n    project_id=custom_vision_project.id,\n    take=250,\n    skip=0\n)\n\n\nprint(f\"There are {len(train_images)} training images in the service.\")\nprint(f\"Each image has a type of {type(train_images[0])}.\")\n\nThere are 203 training images in the service.\nEach image has a type of <class 'azure.cognitiveservices.vision.customvision.training.models._models_py3.Image'>.\n\n\nSome properties of the image class:\n\nimage = train_images[0]\nprint(f\"image.id: {image.id}\")\nprint(f\"image.width: {image.width}\")\nprint(f\"image.height: {image.height}\")\n\nimage.id: 6e274dfc-411a-4bf3-9151-51b96f662248\nimage.width: 1188\nimage.height: 900\n\n\n\nimage.original_image_uri\n\n'https://irisprodeutraining.blob.core.windows.net:443/i-f6cb4ba75bbe46a4883669654dc86f3a/o-6e274dfc411a4bf3915151b96f662248?sv=2020-04-08&se=2022-10-16T22%3A23%3A43Z&sr=b&sp=r&sig=ru8DNhvBrpA46oZtmzNP7CRHSkwGugumb3R%2F3IzJaUE%3D'\n\n\n\nimage.resized_image_uri\n\n'https://irisprodeutraining.blob.core.windows.net:443/i-f6cb4ba75bbe46a4883669654dc86f3a/i-6e274dfc411a4bf3915151b96f662248?sv=2020-04-08&se=2022-10-16T22%3A23%3A43Z&sr=b&sp=r&sig=U5UQ6tjjdLF5gZHFR6wrrWk8B0w9at4cIUeYyxylx2E%3D'\n\n\nOf course there are no tags yet:\n\nprint(f\"image.tags: {image.tags}\")\n\nimage.tags: None\n\n\n\n\nThe images are resized when uploaded\nLet’s see the same image locally:\n\nuploaded_images_df[uploaded_images_df.image_id==image.id]\n\n\n\n\n\n  \n    \n      \n      image_name\n      image_id\n      image_status\n    \n  \n  \n    \n      202\n      torre cerro el pavon 087.jpg\n      6e274dfc-411a-4bf3-9151-51b96f662248\n      OK\n    \n  \n\n\n\n\n\nlocal_image = uploaded_images_df[\n    uploaded_images_df.image_id=='6e274dfc-411a-4bf3-9151-51b96f662248'\n].image_name.item()\nlocal_image\n\n'torre cerro el pavon 087.jpg'\n\n\n\nim = Image.open(pics_folder / local_image)\nim.size\n\n(2576, 1952)\n\n\nThe local image has a size of (2576, 1952) and was resized to (1188, 900) by the service\n\n\nKeep track of original size vs. size in the service\nTo get the real width and height we need to consider EXIF metadata. That’s because local images are sometimes rotated by the viewer with some app viewer.\n\nSize of local images\n\n# The image has some EXIF meta data including information about orientation (rotation)\n# https://stackoverflow.com/a/63950647\n    \nlocal_w = []\nlocal_h = []\n\nfor image in uploaded_images_df.image_name:\n    im = Image.open(pics_folder / image)\n    im = ImageOps.exif_transpose(im)\n\n    local_w.append(im.size[0])\n    local_h.append(im.size[1])\n\n\nlocal_w[:5], local_h[:5]\n\n([640, 1620, 1620, 2160, 2160], [480, 2160, 2160, 1620, 1620])\n\n\n\nuploaded_images_df['ori_w'] = local_w\nuploaded_images_df['ori_h'] = local_h\nuploaded_images_df.head(5)\n\n\n\n\n\n  \n    \n      \n      image_name\n      image_id\n      image_status\n      ori_w\n      ori_h\n    \n  \n  \n    \n      0\n      41.JPG\n      452a0b58-0dc5-41ff-83d1-8d1ae7bd5d1c\n      OK\n      640\n      480\n    \n    \n      1\n      CIMG0030.JPG\n      96b7774e-f5ad-4591-aa71-99ad5c71135e\n      OK\n      1620\n      2160\n    \n    \n      2\n      CIMG0031.JPG\n      3027bc7e-6e21-4b13-a7d7-bb7e08ce6824\n      OK\n      1620\n      2160\n    \n    \n      3\n      CIMG0056.JPG\n      1320ab2e-3405-4853-bd7e-b0ef0f915d4b\n      OK\n      2160\n      1620\n    \n    \n      4\n      CIMG0059.JPG\n      aa67eceb-3db0-4026-bf16-0842c006e6ac\n      OK\n      2160\n      1620\n    \n  \n\n\n\n\n\n\nSize of images in the service\n\nservice_ids = [im.id for im in train_images]\nservice_w = [im.width for im in train_images]\nservice_h = [im.height for im in train_images]\n\n\nservice_w = {id: w for id, w in zip(service_ids, service_w)}\nservice_h = {id: h for id, h in zip(service_ids, service_h)}\n\nuploaded_images_df['train_w'] = uploaded_images_df['image_id'].map(service_w)\nuploaded_images_df['train_h'] = uploaded_images_df['image_id'].map(service_h)\n\n\n\n\nChecking consistency in the ratios\n\nori_ratio = uploaded_images_df.ori_w / uploaded_images_df.ori_h\ntrain_ratio = uploaded_images_df.train_w / uploaded_images_df.train_h\nall(abs(ori_ratio - i_ratio) > .3)\n\nFalse\n\n\nImages that has an inconsistent ratio:\n\nuploaded_images_df[abs(ori_ratio - train_ratio) > 0.1]\n\n\n\n\n\n  \n    \n      \n      image_name\n      image_id\n      image_status\n      ori_w\n      ori_h\n      train_w\n      train_h\n    \n  \n  \n    \n      179\n      TORRE EL TIGRITO 01.jpg\n      2563fffe-d621-4799-8e81-6ad57049cdaa\n      OK\n      480\n      640\n      640\n      480\n    \n  \n\n\n\n\n\nim = Image.open( pics_folder / 'TORRE EL TIGRITO 01.jpg' )\nshow_img(im);\n\n\n\n\n\nim.size\n\n(640, 480)\n\n\nImageOps.exif_transpose failed for this image.\nBut if you don’t use it, more images would be inconsistent.\nIf seems that exif_transpose keep track of manually rotated images.\n\nim = ImageOps.exif_transpose(im)\nim.size\n\n(480, 640)\n\n\n\nfilter = uploaded_images_df.image_id == '2563fffe-d621-4799-8e81-6ad57049cdaa'\nuploaded_images_df.loc[filter, ['ori_w', 'ori_h']] = (640, 480)\nuploaded_images_df[filter]\n\n\n\n\n\n  \n    \n      \n      image_name\n      image_id\n      image_status\n      ori_w\n      ori_h\n      train_w\n      train_h\n    \n  \n  \n    \n      179\n      TORRE EL TIGRITO 01.jpg\n      2563fffe-d621-4799-8e81-6ad57049cdaa\n      OK\n      640\n      480\n      640\n      480\n    \n  \n\n\n\n\n\n\nExporting csv with size data\n\nuploaded_images_df.sample(10)\n\n\n\n\n\n  \n    \n      \n      image_name\n      image_id\n      image_status\n      ori_w\n      ori_h\n      train_w\n      train_h\n    \n  \n  \n    \n      155\n      P1100700.JPG\n      b10efb57-70a4-48d6-a846-121ded4546f8\n      OK\n      2048\n      1360\n      1355\n      900\n    \n    \n      7\n      CUMACA 11.jpg\n      2c55467b-5de5-4329-91d2-a2fafdedd080\n      OK\n      2592\n      1944\n      1200\n      900\n    \n    \n      49\n      IMG_1170.JPG\n      ce2177ae-d03e-4a61-9dfb-4229542572fe\n      OK\n      480\n      640\n      480\n      640\n    \n    \n      141\n      MVC-024S.JPG\n      9ba84daa-e00c-4975-a07b-3ae23ef8f884\n      OK\n      640\n      480\n      640\n      480\n    \n    \n      136\n      Imagen008.jpg\n      c861b4de-127a-4dc0-84ea-9cb96fb380f2\n      OK\n      640\n      480\n      640\n      480\n    \n    \n      202\n      torre cerro el pavon 087.jpg\n      6e274dfc-411a-4bf3-9151-51b96f662248\n      OK\n      2576\n      1952\n      1188\n      900\n    \n    \n      145\n      P1100611.JPG\n      1148d437-fc44-4c51-af4a-4751e242b3b7\n      OK\n      2048\n      1360\n      1355\n      900\n    \n    \n      147\n      P1100613.JPG\n      c9dab11e-0663-42f8-8c93-4e2351b15d4c\n      OK\n      2048\n      1360\n      1355\n      900\n    \n    \n      171\n      PICT0386.JPG\n      0e51a561-b938-48f6-8bc6-3c3bf4c72c44\n      OK\n      2560\n      1920\n      1200\n      900\n    \n    \n      142\n      MVC-025S.JPG\n      a8c2a746-2a65-4872-b7b5-0bd5edf965c9\n      OK\n      640\n      480\n      640\n      480\n    \n  \n\n\n\n\n\nuploaded_images_df.to_csv('20221015_203_Images_Uploaded_WxH.csv', index=False)"
  },
  {
    "objectID": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_1.html#conslusions",
    "href": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_1.html#conslusions",
    "title": "Telecom Equipment Detection with Azure Custom Vision (Free) - Part 1",
    "section": "Conslusions",
    "text": "Conslusions\n\nIt was straightforward to upload images to the service.\nBig images got resized, but their ratios were kept.\nexif_transpose needs to be used to get the real width and height of the image, but failed with one of them."
  },
  {
    "objectID": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_2.html",
    "href": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_2.html",
    "title": "Telecom Equipment Detection with Azure Custom Vision (Free) - Part 2",
    "section": "",
    "text": "Part 2. Label images with Smart Labeler"
  },
  {
    "objectID": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_2.html#introduction",
    "href": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_2.html#introduction",
    "title": "Telecom Equipment Detection with Azure Custom Vision (Free) - Part 2",
    "section": "Introduction",
    "text": "Introduction\nIn this series of posts we are going to follow along the process and code required to train an object detection model using Azure Custom Vision (in its free tier).\n-> We are going to use real world pictures compiled from work I have done over the years in Venezuela. In this kind of supervised learning problem we need tagged images. So we will use Smart Labeler to do that.\nAfter the model is published in Azure service, we can use the API to build and share a demo with Gradio and Huggingface.\nHere is the one that is already published for you to try:\nTelecom-Object-Detection\n\nThe model will be trained to detect the following objects:\n\nGrid Antenna\nPanel antenna\nRadome antenna\nRRU\nShroud antenna\nSolid antenna\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrid\n\n\nPanel\n\n\nRadome\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRRU\n\n\nShroud\n\n\nSolid"
  },
  {
    "objectID": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_2.html#tutorial-parts",
    "href": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_2.html#tutorial-parts",
    "title": "Telecom Equipment Detection with Azure Custom Vision (Free) - Part 2",
    "section": "Tutorial Parts",
    "text": "Tutorial Parts\n\nPart 1 will cover:\n\nCreating a free Azure Custom Vision Service.\nUploading the images to the service.\n\nPart 2 will cover:\n\nAnalyzing what happens to the images after uploading.\nHow to label the images using Smart Labeler\nTraining and publishing the model.\n\nPart 3 will cover:\n\nCreate a Huggingface Gradio Demo."
  },
  {
    "objectID": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_2.html#references",
    "href": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_2.html#references",
    "title": "Telecom Equipment Detection with Azure Custom Vision (Free) - Part 2",
    "section": "References",
    "text": "References\n\nCustom Vision Documentation: Label images faster with Smart Labeler\nMicrosoft Learn Excersice: Detect Objects in Images with Custom Vision\nCustom Vision Documentation: Quickstart: Create an object detection project with the Custom Vision client library\nREST API Endpoint: Custom Vision REST API reference - Azure Cognitive Services\nAPIs Documentation: Custom_Vision_Training_3.3\nAzure SDK for Python: Custom Vision Client Library\nSource Code: Azure/azure-sdk-for-python"
  },
  {
    "objectID": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_2.html#part-2.1.-labeling-the-images",
    "href": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_2.html#part-2.1.-labeling-the-images",
    "title": "Telecom Equipment Detection with Azure Custom Vision (Free) - Part 2",
    "section": "Part 2.1. Labeling the Images",
    "text": "Part 2.1. Labeling the Images\nSmart Labeler is a simple tool for labeling images. It can be used for classification and object detection problems. When working in this problem I missed the ability to zoom-in when labeling some small objects.\nFor speeding up bigger projects it might be usefull that you can first label some pictures, then train and get suggestions for the untagged images, but I didn’t use it. By default the labeler tries to give suggestions even without training.\nThe process is simple and you can the use the annotation to train models outside the service (as we are going to try after this serie, using fastai).\n\nInstall and import libraries\nWe need to install Custom Vision’s Python SDK and python-dotenv:\n! pip install azure-cognitiveservices-vision-customvision==3.1.0\n! pip install python-dotenv\n\nfrom azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\nfrom azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry, Region, ImageRegionCreateEntry\nfrom msrest.authentication import ApiKeyCredentials\nimport time\nimport json\nimport os\n\nimport pandas as pd\nimport numpy as np\nfrom dotenv import load_dotenv\nfrom pathlib import Path\n\nfrom PIL import Image, ImageOps\nfrom PIL import UnidentifiedImageError\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches, patheffects\n\n\n\nCredentials and services\n\nApiKeyCredentials\nCustomVisionTrainingClient\nCustomVisionTrainingClient.get_project()\n\n\nDOTENV_PATH = './.env'\n\n\nload_dotenv(DOTENV_PATH)\ntraining_endpoint = os.getenv('TrainingEndpoint')\ntraining_key = os.getenv('TrainingKey')\nproject_id = os.getenv('ProjectID')\n\ncredentials = ApiKeyCredentials(in_headers={\"Training-key\": training_key})\ntraining_client = CustomVisionTrainingClient(training_endpoint, credentials)\ncustom_vision_project = training_client.get_project(project_id)\n\n\n\nCreating Labels\nSince I already did the manual tagging, we can use those tags in this new project.\nFirst we need to create the labels/tags in the service: - CustomVisionTrainingClient.create_tag()\n\ntags = ['Grid', 'Panel', 'Radome', 'RRU', 'Shroud', 'Solid']\ndesc = ['Grid Antenna', 'Panel Cel. Antenna', 'Radome Antenna', \n        'RRU Equipment', 'Shroud Antenna', 'Solid Antenna']\n\n\nservice_tags = []\nfor i, tag in enumerate(tags):\n    service_tags.append(\n        training_client.create_tag(\n            project_id=project_id, name=tag,\n            description=desc[i]\n        )\n    )\nservice_tags\n\n[<azure.cognitiveservices.vision.customvision.training.models._models_py3.Tag>,\n <azure.cognitiveservices.vision.customvision.training.models._models_py3.Tag>,\n <azure.cognitiveservices.vision.customvision.training.models._models_py3.Tag>,\n <azure.cognitiveservices.vision.customvision.training.models._models_py3.Tag>,\n <azure.cognitiveservices.vision.customvision.training.models._models_py3.Tag>,\n <azure.cognitiveservices.vision.customvision.training.models._models_py3.Tag>]\n\n\nNow we can see this in the service:\n\n\nservice_tag_ids = {tag.name: tag.id for tag in service_tags}\nservice_tag_ids\n\n{'Grid': 'e016b6a4-49e6-4897-a0c7-d8fc64d032f1',\n 'Panel': 'c9b15b62-6823-44a4-8fee-fa9d84e65a7e',\n 'Radome': 'a1020654-79c5-4d8a-867c-93dfb2a4a81d',\n 'RRU': '91ffb5b0-fe25-4d72-9c65-14793183a3b9',\n 'Shroud': '4e413c15-141a-419b-a958-1485008b2904',\n 'Solid': '3f13d9b0-7b4d-4679-8fb8-7855cea0a118'}\n\n\n\n\nUpload Regions from json file\nAs I pointed before, you can create all the regions with Smart Labeler. Since I did that already in a previos project, I updated the region’s image ids and tags to the ones in this project and save them as a json.\n\nCustomVisionTrainingClient.create_image_regions()\n\nWe can see from the documentation that “There is a limit of 64 entries in a batch.”\n\nwith open(\"20221016_CreateImageRegions_Body.json\") as json_file:\n    regions_dict = json.load(json_file)\n\nprint(f'We have a total of {len(regions_dict[\"regions\"]):_} regions.')\nprint()\nprint('The first two regions:')\nregions_dict['regions'][:2]\n\nWe have a total of 1_279 regions.\n\nThe first two regions:\n\n\n[{'imageId': '6e274dfc-411a-4bf3-9151-51b96f662248',\n  'tagId': '91ffb5b0-fe25-4d72-9c65-14793183a3b9',\n  'left': 0.6395582,\n  'top': 0,\n  'width': 0.10740108,\n  'height': 0.14776269},\n {'imageId': '6e274dfc-411a-4bf3-9151-51b96f662248',\n  'tagId': 'c9b15b62-6823-44a4-8fee-fa9d84e65a7e',\n  'left': 0.772766,\n  'top': 0.16059849,\n  'width': 0.22664931,\n  'height': 0.40633526}]\n\n\n\n# Create batches of 60 regions\n\nregions = regions_dict['regions']\n\nfor i in range(int(1_279 / 60)+1):\n    \n    batch_regions = []\n    print(f'Creating Regions {i*60+1:>{5}_} to {min((i+1)*60, 1_279):>{5}_}')\n    \n    for region in regions[i*60: (i+1)*60]:\n        batch_regions.append(\n            ImageRegionCreateEntry(\n                image_id=region['imageId'],\n                tag_id=region['tagId'],\n                left=region['left'], top=region['top'],\n                width=region['width'], height=region['height']\n        ))\n\n    training_client.create_image_regions(\n        project_id=project_id, \n        regions=batch_regions\n    )\n\nCreating Regions     1 to    60\nCreating Regions    61 to   120\nCreating Regions   121 to   180\nCreating Regions   181 to   240\nCreating Regions   241 to   300\nCreating Regions   301 to   360\nCreating Regions   361 to   420\nCreating Regions   421 to   480\nCreating Regions   481 to   540\nCreating Regions   541 to   600\nCreating Regions   601 to   660\nCreating Regions   661 to   720\nCreating Regions   721 to   780\nCreating Regions   781 to   840\nCreating Regions   841 to   900\nCreating Regions   901 to   960\nCreating Regions   961 to 1_020\nCreating Regions 1_021 to 1_080\nCreating Regions 1_081 to 1_140\nCreating Regions 1_141 to 1_200\nCreating Regions 1_201 to 1_260\nCreating Regions 1_261 to 1_279\n\n\nExample image in the service:\n\n\n\nVerifying the number of created Regions\n\nall_tagged_images = training_client.get_images(\n    project_id=project_id,\n    tagging_status=\"Tagged\", \n    take=250   # Max 256\n)\ni = 0\nfor im in all_tagged_images: i += len(im.regions)\nprint(f\"Number of created Regions: {i:_}\")\n\nNumber of created Regions: 1_279\n\n\n\n\nDraw some regions\n\nimages_df = pd.read_csv('20221015_203_Images_Uploaded_WxH.csv')\nimages_df.index = images_df.image_id\nimages_df.head(5)\n\n\n\n\n\n  \n    \n      \n      image_name\n      image_id\n      image_status\n      ori_w\n      ori_h\n      train_w\n      train_h\n    \n    \n      image_id\n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      452a0b58-0dc5-41ff-83d1-8d1ae7bd5d1c\n      41.JPG\n      452a0b58-0dc5-41ff-83d1-8d1ae7bd5d1c\n      OK\n      640\n      480\n      640\n      480\n    \n    \n      96b7774e-f5ad-4591-aa71-99ad5c71135e\n      CIMG0030.JPG\n      96b7774e-f5ad-4591-aa71-99ad5c71135e\n      OK\n      1620\n      2160\n      900\n      1200\n    \n    \n      3027bc7e-6e21-4b13-a7d7-bb7e08ce6824\n      CIMG0031.JPG\n      3027bc7e-6e21-4b13-a7d7-bb7e08ce6824\n      OK\n      1620\n      2160\n      900\n      1200\n    \n    \n      1320ab2e-3405-4853-bd7e-b0ef0f915d4b\n      CIMG0056.JPG\n      1320ab2e-3405-4853-bd7e-b0ef0f915d4b\n      OK\n      2160\n      1620\n      1200\n      900\n    \n    \n      aa67eceb-3db0-4026-bf16-0842c006e6ac\n      CIMG0059.JPG\n      aa67eceb-3db0-4026-bf16-0842c006e6ac\n      OK\n      2160\n      1620\n      1200\n      900\n    \n  \n\n\n\n\nCreate a dictionary to easily access all regions from an image id:\n\nimg2ann = dict()\n\nfor image in all_tagged_images:\n    img2ann[image.id] = tuple([list(), list()])\n    image_w = image.width; image_h = image.height\n    ori_w = images_df.loc[image.id].ori_w\n    ori_h = images_df.loc[image.id].ori_h\n    for region in image.regions:\n        img2ann[image.id][1].append(region.tag_name)\n        img2ann[image.id][0].append([\n            region.left*ori_w, \n            region.top*ori_h, \n            region.width*ori_w, \n            region.height*ori_h\n        ])\n\n\npics_folder = Path('./train_images')\n\n\n# https://youtu.be/Z0ssNAbe81M?t=4636\ndef show_img(im, figsize=None, ax=None):\n    if not ax: fig, ax = plt.subplots(figsize=figsize)\n    ax.imshow(im)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    return ax\n\ndef draw_outline(o, lw):\n    o.set_path_effects([patheffects.Stroke(\n        linewidth=lw, foreground='black'), patheffects.Normal()\n    ])\n\ndef draw_rect(ax, b):\n    patch = ax.add_patch(\n        patches.Rectangle(b[:2], *b[-2:], fill=False, edgecolor='white', lw=1)\n    )\n    draw_outline(patch, 4)\n\ndef draw_text(ax, xy, txt, sz=14):\n    text = ax.text(*xy, txt,\n        verticalalignment='top', color='white', fontsize=sz, weight='bold')\n    draw_outline(text, 1)\n\n\ndef draw_regions(index=0):\n    im = Image.open( pics_folder / images_df.iloc[index].image_name )\n    ax = show_img(im, figsize=(8,8))\n\n    reg, lab = img2ann[images_df.iloc[index].image_id]\n    for idx, region in enumerate(reg):\n        draw_rect(ax, np.array(region))\n        tag = lab[idx]\n        draw_text(ax, region[:2], tag)\n\n\ndraw_regions(index=0)\n\n\n\n\nA dragon-fly was cought in that picture!\n\ndraw_regions(index=100)"
  },
  {
    "objectID": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_2.html#part-2.2.-train-and-test-a-model",
    "href": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_2.html#part-2.2.-train-and-test-a-model",
    "title": "Telecom Equipment Detection with Azure Custom Vision (Free) - Part 2",
    "section": "Part 2.2. Train and Test a Model",
    "text": "Part 2.2. Train and Test a Model\n\nCustomVisionTrainingClient.train_project()\n\n\ntrain_iteration = training_client.train_project(\n    project_id=project_id,\n    training_type='Regular'\n)\n\n\nExplore pictures\n\npics_folder = Path('./train_images')\n\npictures = sorted(list(pics_folder.iterdir()))\n\nprint(f\"There are {len(pictures)} pictures\")\n\nThere are 203 pictures\n\n\n\nfig, axes = plt.subplots(3, 4, figsize=(16, 12))\n\ndef show_img(im, figsize=None, ax=None):\n    if not ax: fig, ax = plt.subplots(figsize=figsize)\n    ax.imshow(im)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    return ax\n\nfor i, ax in enumerate(axes.flat):\n    im = Image.open( pictures[i*10] )\n    ax = show_img(im, ax=ax)\n\n\n\n\nAs you can see the pictures are very varied. Different cameras, lighting conditions, focus, resolutions and sizes…\n\n\nUpload the pictures to Custom Vision Service\n\nuploaded_images_df = pd.DataFrame(columns=[\"image_name\", \"image_id\", \"image_status\"])\n\n\nupload_batch = Upload_Images_1by1(pictures)\n\n\nuploaded_images_df = pd.DataFrame(upload_batch)\nuploaded_images_df\n\n\n\n\n\n  \n    \n      \n      image_name\n      image_id\n      image_status\n    \n  \n  \n    \n      0\n      41.JPG\n      452a0b58-0dc5-41ff-83d1-8d1ae7bd5d1c\n      OK\n    \n    \n      1\n      CIMG0030.JPG\n      96b7774e-f5ad-4591-aa71-99ad5c71135e\n      OK\n    \n    \n      2\n      CIMG0031.JPG\n      3027bc7e-6e21-4b13-a7d7-bb7e08ce6824\n      OK\n    \n    \n      3\n      CIMG0056.JPG\n      1320ab2e-3405-4853-bd7e-b0ef0f915d4b\n      OK\n    \n    \n      4\n      CIMG0059.JPG\n      aa67eceb-3db0-4026-bf16-0842c006e6ac\n      OK\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      198\n      torre cerro el pavon 075.jpg\n      b6dd061a-a68d-4d91-a39f-711968445571\n      OK\n    \n    \n      199\n      torre cerro el pavon 080.jpg\n      d12264cf-3d7b-469c-9445-da8dce8dabef\n      OK\n    \n    \n      200\n      torre cerro el pavon 085.jpg\n      c6d587fe-5f3a-46ea-bc04-7ff54f10b4ae\n      OK\n    \n    \n      201\n      torre cerro el pavon 086.jpg\n      ea34cbad-8d50-4b5f-aed0-91d7fe40a754\n      OK\n    \n    \n      202\n      torre cerro el pavon 087.jpg\n      6e274dfc-411a-4bf3-9151-51b96f662248\n      OK\n    \n  \n\n203 rows × 3 columns\n\n\n\n\nprint(f\"{sum(uploaded_images_df.image_status != 'OK')} \n      images failed when uploading\")\n\n0 images failed uploading\n\n\nSave a csv:\n\nuploaded_images_df.to_csv('20221012_203_Images_Uploaded.csv', index=False)"
  },
  {
    "objectID": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_2.html#part-1.3.-explore-data-from-custom-vision-service",
    "href": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_2.html#part-1.3.-explore-data-from-custom-vision-service",
    "title": "Telecom Equipment Detection with Azure Custom Vision (Free) - Part 2",
    "section": "Part 1.3. Explore Data from Custom Vision Service",
    "text": "Part 1.3. Explore Data from Custom Vision Service\n\nGet id’s of uploaded images\n\nCustomVisionTrainingClient.get_images()\n\n\ntrain_images = training_client.get_images(\n    project_id=custom_vision_project.id,\n    take=250,\n    skip=0\n)\n\n\nprint(f\"There are {len(train_images)} training images in the service.\")\nprint(f\"Each image has a type of {type(train_images[0])}.\")\n\nThere are 203 training images in the service.\nEach image has a type of <class 'azure.cognitiveservices.vision.customvision.training.models._models_py3.Image'>.\n\n\nSome properties of the image class:\n\nimage = train_images[0]\nprint(f\"image.id: {image.id}\")\nprint(f\"image.width: {image.width}\")\nprint(f\"image.height: {image.height}\")\n\nimage.id: 6e274dfc-411a-4bf3-9151-51b96f662248\nimage.width: 1188\nimage.height: 900\n\n\n\nimage.original_image_uri\n\n'https://irisprodeutraining.blob.core.windows.net:443/i-f6cb4ba75bbe46a4883669654dc86f3a/o-6e274dfc411a4bf3915151b96f662248?sv=2020-04-08&se=2022-10-16T22%3A23%3A43Z&sr=b&sp=r&sig=ru8DNhvBrpA46oZtmzNP7CRHSkwGugumb3R%2F3IzJaUE%3D'\n\n\n\nimage.resized_image_uri\n\n'https://irisprodeutraining.blob.core.windows.net:443/i-f6cb4ba75bbe46a4883669654dc86f3a/i-6e274dfc411a4bf3915151b96f662248?sv=2020-04-08&se=2022-10-16T22%3A23%3A43Z&sr=b&sp=r&sig=U5UQ6tjjdLF5gZHFR6wrrWk8B0w9at4cIUeYyxylx2E%3D'\n\n\nOf course there are no tags yet:\n\nprint(f\"image.tags: {image.tags}\")\n\nimage.tags: None\n\n\n\n\nThe images are resized when uploaded\nLet’s see the same image locally:\n\nuploaded_images_df[uploaded_images_df.image_id==image.id]\n\n\n\n\n\n  \n    \n      \n      image_name\n      image_id\n      image_status\n    \n  \n  \n    \n      202\n      torre cerro el pavon 087.jpg\n      6e274dfc-411a-4bf3-9151-51b96f662248\n      OK\n    \n  \n\n\n\n\n\nlocal_image = uploaded_images_df[\n    uploaded_images_df.image_id=='6e274dfc-411a-4bf3-9151-51b96f662248'\n].image_name.item()\nlocal_image\n\n'torre cerro el pavon 087.jpg'\n\n\n\nim = Image.open(pics_folder / local_image)\nim.size\n\n(2576, 1952)\n\n\nThe local image has a size of (2576, 1952) and was resized to (1188, 900) by the service\n\n\nKeep track of original size vs. size in the service\nTo get the real width and height we need to consider EXIF metadata. That’s because local images are sometimes rotated by the viewer with some app viewer.\n\nSize of local images\n\n# The image has some EXIF meta data including information about orientation (rotation)\n# https://stackoverflow.com/a/63950647\n    \nlocal_w = []\nlocal_h = []\n\nfor image in uploaded_images_df.image_name:\n    im = Image.open(pics_folder / image)\n    im = ImageOps.exif_transpose(im)\n\n    local_w.append(im.size[0])\n    local_h.append(im.size[1])\n\n\nlocal_w[:5], local_h[:5]\n\n([640, 1620, 1620, 2160, 2160], [480, 2160, 2160, 1620, 1620])\n\n\n\nuploaded_images_df['ori_w'] = local_w\nuploaded_images_df['ori_h'] = local_h\nuploaded_images_df.head(5)\n\n\n\n\n\n  \n    \n      \n      image_name\n      image_id\n      image_status\n      ori_w\n      ori_h\n    \n  \n  \n    \n      0\n      41.JPG\n      452a0b58-0dc5-41ff-83d1-8d1ae7bd5d1c\n      OK\n      640\n      480\n    \n    \n      1\n      CIMG0030.JPG\n      96b7774e-f5ad-4591-aa71-99ad5c71135e\n      OK\n      1620\n      2160\n    \n    \n      2\n      CIMG0031.JPG\n      3027bc7e-6e21-4b13-a7d7-bb7e08ce6824\n      OK\n      1620\n      2160\n    \n    \n      3\n      CIMG0056.JPG\n      1320ab2e-3405-4853-bd7e-b0ef0f915d4b\n      OK\n      2160\n      1620\n    \n    \n      4\n      CIMG0059.JPG\n      aa67eceb-3db0-4026-bf16-0842c006e6ac\n      OK\n      2160\n      1620\n    \n  \n\n\n\n\n\n\nSize of images in the service\n\nservice_ids = [im.id for im in train_images]\nservice_w = [im.width for im in train_images]\nservice_h = [im.height for im in train_images]\n\n\nservice_w = {id: w for id, w in zip(service_ids, service_w)}\nservice_h = {id: h for id, h in zip(service_ids, service_h)}\n\nuploaded_images_df['train_w'] = uploaded_images_df['image_id'].map(service_w)\nuploaded_images_df['train_h'] = uploaded_images_df['image_id'].map(service_h)\n\n\n\n\nChecking consistency in the ratios\n\nori_ratio = uploaded_images_df.ori_w / uploaded_images_df.ori_h\ntrain_ratio = uploaded_images_df.train_w / uploaded_images_df.train_h\nall(abs(ori_ratio - i_ratio) > .3)\n\nFalse\n\n\nImages that has an inconsistent ratio:\n\nuploaded_images_df[abs(ori_ratio - train_ratio) > 0.1]\n\n\n\n\n\n  \n    \n      \n      image_name\n      image_id\n      image_status\n      ori_w\n      ori_h\n      train_w\n      train_h\n    \n  \n  \n    \n      179\n      TORRE EL TIGRITO 01.jpg\n      2563fffe-d621-4799-8e81-6ad57049cdaa\n      OK\n      480\n      640\n      640\n      480\n    \n  \n\n\n\n\n\nim = Image.open( pics_folder / 'TORRE EL TIGRITO 01.jpg' )\nshow_img(im);\n\n\n\n\n\nim.size\n\n(640, 480)\n\n\nImageOps.exif_transpose failed for this image.\nBut if you don’t use it, more images would be inconsistent.\nIf seems that exif_transpose keep track of manually rotated images.\n\nim = ImageOps.exif_transpose(im)\nim.size\n\n(480, 640)\n\n\n\nfilter = uploaded_images_df.image_id == '2563fffe-d621-4799-8e81-6ad57049cdaa'\nuploaded_images_df.loc[filter, ['ori_w', 'ori_h']] = (640, 480)\nuploaded_images_df[filter]\n\n\n\n\n\n  \n    \n      \n      image_name\n      image_id\n      image_status\n      ori_w\n      ori_h\n      train_w\n      train_h\n    \n  \n  \n    \n      179\n      TORRE EL TIGRITO 01.jpg\n      2563fffe-d621-4799-8e81-6ad57049cdaa\n      OK\n      640\n      480\n      640\n      480\n    \n  \n\n\n\n\n\n\nExporting csv with size data\n\nuploaded_images_df.sample(10)\n\n\n\n\n\n  \n    \n      \n      image_name\n      image_id\n      image_status\n      ori_w\n      ori_h\n      train_w\n      train_h\n    \n  \n  \n    \n      155\n      P1100700.JPG\n      b10efb57-70a4-48d6-a846-121ded4546f8\n      OK\n      2048\n      1360\n      1355\n      900\n    \n    \n      7\n      CUMACA 11.jpg\n      2c55467b-5de5-4329-91d2-a2fafdedd080\n      OK\n      2592\n      1944\n      1200\n      900\n    \n    \n      49\n      IMG_1170.JPG\n      ce2177ae-d03e-4a61-9dfb-4229542572fe\n      OK\n      480\n      640\n      480\n      640\n    \n    \n      141\n      MVC-024S.JPG\n      9ba84daa-e00c-4975-a07b-3ae23ef8f884\n      OK\n      640\n      480\n      640\n      480\n    \n    \n      136\n      Imagen008.jpg\n      c861b4de-127a-4dc0-84ea-9cb96fb380f2\n      OK\n      640\n      480\n      640\n      480\n    \n    \n      202\n      torre cerro el pavon 087.jpg\n      6e274dfc-411a-4bf3-9151-51b96f662248\n      OK\n      2576\n      1952\n      1188\n      900\n    \n    \n      145\n      P1100611.JPG\n      1148d437-fc44-4c51-af4a-4751e242b3b7\n      OK\n      2048\n      1360\n      1355\n      900\n    \n    \n      147\n      P1100613.JPG\n      c9dab11e-0663-42f8-8c93-4e2351b15d4c\n      OK\n      2048\n      1360\n      1355\n      900\n    \n    \n      171\n      PICT0386.JPG\n      0e51a561-b938-48f6-8bc6-3c3bf4c72c44\n      OK\n      2560\n      1920\n      1200\n      900\n    \n    \n      142\n      MVC-025S.JPG\n      a8c2a746-2a65-4872-b7b5-0bd5edf965c9\n      OK\n      640\n      480\n      640\n      480\n    \n  \n\n\n\n\n\nuploaded_images_df.to_csv('20221015_203_Images_Uploaded_WxH.csv', index=False)"
  },
  {
    "objectID": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_2.html#conslusions",
    "href": "posts/object-detection-with-azure-custom-vision/ObjectDetectionWithAzureCustomVision_Part_2.html#conslusions",
    "title": "Telecom Equipment Detection with Azure Custom Vision (Free) - Part 2",
    "section": "Conslusions",
    "text": "Conslusions\n\nIt was straightforward to upload images to the service.\nBig images got resized, but their ratios were kept.\nexif_transpose needs to be used to get the real width and height of the image, but failed with one of them."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Since this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  }
]