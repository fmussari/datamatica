{
 "cells": [
  {
   "cell_type": "raw",
   "id": "12358242",
   "metadata": {},
   "source": [
    "---\n",
    "title: Gladia API using `asyncio` and `aiohttp `with Python\n",
    "author: \"Francisco Mussari\"  \n",
    "date: 2024-03-19  \n",
    "image: \"gladia.PNG\"\n",
    "categories: [Whisper, Transcription, asyncio, aiohttp]  \n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    toc-depth: 3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594c1ff2",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### Discovering Gladia\n",
    "\n",
    "[Gladia](https://www.gladia.io/) unveils a great \"Speech-to-Text\" service, powered by their [Whisper-Zero](https://www.gladia.io/whisper-zero) ASR technology. You can begin this exploration free with a generous 10 hours of audio transcriptions per month.\n",
    "\n",
    "### Usage and Documentation\n",
    "\n",
    "While Gladia's [documentation and API reference](https://docs.gladia.io/chapters/introduction/pages/introduction) offers Python examples for both pre-recorded and live (streaming) scenarios, a crucial element remains unaddressed: integration with Python's asyncio.\n",
    "  \n",
    "### Asyncio with Gladia\n",
    "\n",
    "This post delves into harnessing asyncio with the Gladia API, enabling applications to execute multiple tasks in parallel.   \n",
    "  \n",
    "We'll navigate into through the transcription process, which involves several I/O bound tasks: \n",
    "\n",
    "1. Uploading audio files\n",
    "2. Initiating the transcription job\n",
    "3. Awaiting completion of the transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670bd186",
   "metadata": {},
   "source": [
    "## Configuring your account\n",
    "\n",
    "You can go to the [Getting Started](https://docs.gladia.io/chapters/get-started/pages/configure-account) section in the documentation to configure your account and get an API key."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60786d0a",
   "metadata": {},
   "source": [
    "## Resources\n",
    "- [Gladia Documentation](https://docs.gladia.io/chapters/introduction/pages/introduction)\n",
    "- [Gladia samples: python](https://github.com/gladiaio/gladia-samples/tree/main/python)\n",
    "- [Batch Processing OpenAI using asyncio and Instructor with Python](https://jxnl.github.io/instructor/blog/2023/11/13/learn-async/)\n",
    "- In creating this guide, I leveraged Gemini and mostly ChatGPT, tools that helped me, a non-native English speaker, refine my ideas and express them clearly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de66477f",
   "metadata": {},
   "source": [
    "## Asyncio with Gladia: A Step-by-Step Guide\n",
    "\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82d2c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: true\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import requests\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# This two lines allow asyncio to be used in Jupyter Notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ae0dbc",
   "metadata": {},
   "source": [
    "### Get API Key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4316ce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"google.colab\" in sys.modules:\n",
    "    # If running in Colab\n",
    "    from google.colab import userdata\n",
    "    x_gladia_key = userdata.get('GLADIA_API_KEY')\n",
    "else:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv(\"creds/.env\")\n",
    "    x_gladia_key = os.environ.get('GLADIA_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699cefb3",
   "metadata": {},
   "source": [
    "### Context manager to measure time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0cdc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/69156219\n",
    "\n",
    "class catchtime:\n",
    "    def __enter__(self):\n",
    "        self.start = perf_counter()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self.seconds = round(perf_counter() - self.start, 2)\n",
    "        m, s = divmod(self.seconds, 60)\n",
    "        self.m, self.s = int(m), round(s, 1)\n",
    "        self.readout = f'Time: {self.seconds:.3f} seconds'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa41e48e",
   "metadata": {},
   "source": [
    "### Python Async Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781cf91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_response(\n",
    "    response: aiohttp.client_reqrep.ClientResponse\n",
    ") -> Optional[dict]:\n",
    "    \"\"\"Process aiohttp requests\n",
    "    \"\"\"\n",
    "    if response.status not in (200, 201):\n",
    "        print(f\"- Request failed with status: {response.status}\")\n",
    "        json_response = await response.text()\n",
    "        print(f\"Json Response: {json_response}\")\n",
    "        print('- End of work');\n",
    "        return None\n",
    "    else:\n",
    "        print(\"- Request successful\")\n",
    "        return await response.json()\n",
    "\n",
    "\n",
    "async def async_make_request(\n",
    "    session: aiohttp.client.ClientSession, \n",
    "    url: str, headers: dict, \n",
    "    method: str = \"GET\", \n",
    "    data: aiohttp.formdata.FormData = None, \n",
    "    json: dict = None\n",
    ") -> Optional[dict]:\n",
    "    \"\"\"Send aiohttp requests\n",
    "    \"\"\"\n",
    "    if method == \"POST\":\n",
    "        async with session.post(\n",
    "            url, headers=headers, data=data, json=json\n",
    "        ) as response:\n",
    "            return await process_response(response)\n",
    "    else:\n",
    "        async with session.get(url, headers=headers) as response:\n",
    "            return await process_response(response)\n",
    "\n",
    "\n",
    "async def a_upload_file(\n",
    "    session: aiohttp.client.ClientSession, \n",
    "    file_path: Path\n",
    ") -> dict:\n",
    "    \"\"\"Upload audio file to Gladia\n",
    "    \"\"\"\n",
    "\n",
    "    with catchtime() as t:\n",
    "        file_name = str(file_path.with_suffix(''))\n",
    "        content_type = f\"audio/{file_path.suffix[1:]}\"\n",
    "\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            data = aiohttp.FormData()\n",
    "            data.add_field(\"audio\", f, filename=file_name, content_type=content_type)\n",
    "\n",
    "            print(\"- Uploading file to Gladia...\")\n",
    "            json_response = await async_make_request(\n",
    "                session, \"https://api.gladia.io/v2/upload/\",\n",
    "                headers=headers,  method=\"POST\", data=data\n",
    "            )\n",
    "\n",
    "    print(f'Upload Time: {t.seconds} seconds for `{file_path.name}`')\n",
    "\n",
    "    return json_response\n",
    "\n",
    "\n",
    "async def a_create_transcription_job(\n",
    "    session: aiohttp.client.ClientSession,\n",
    "    audio_url: str,\n",
    "    diarization: bool = False,\n",
    "    enable_code_switching: bool = False,\n",
    "    custom_metadata: Optional[dict] = None,\n",
    "    **kwargs\n",
    ") -> str:\n",
    "    \"\"\"Initiate the transcription job\n",
    "    \"\"\"\n",
    "\n",
    "    json_data = {\n",
    "        \"audio_url\": audio_url,\n",
    "        \"diarization\": diarization,\n",
    "        \"enable_code_switching\": enable_code_switching,\n",
    "        \"custom_metadata\": custom_metadata\n",
    "    }\n",
    "    for key in kwargs.keys():\n",
    "        data[key] = kwargs[key]\n",
    "\n",
    "    print(\"- Sending transcription request to Gladia API...\")\n",
    "\n",
    "    with catchtime() as t:\n",
    "        json_response = await async_make_request(\n",
    "            session, \"https://api.gladia.io/v2/transcription/\",\n",
    "            headers=headers,  method=\"POST\", json=json_data\n",
    "        )\n",
    "\n",
    "    print(f'Create Transcription Job: {t.seconds} seconds for `{audio_url}`')\n",
    "\n",
    "    return json_response\n",
    "\n",
    "\n",
    "async def a_wait_until_job_done(\n",
    "    session: aiohttp.client.ClientSession,\n",
    "    transcription_job: dict\n",
    "):\n",
    "    \"\"\"Wait until the transcription job is done\n",
    "    \"\"\"\n",
    "\n",
    "    result_url = transcription_job.get(\"result_url\")\n",
    "    id = transcription_job[\"id\"]\n",
    "\n",
    "    while True:\n",
    "        poll_response = await async_make_request(\n",
    "            session, url=result_url, headers=headers\n",
    "        )\n",
    "\n",
    "        if poll_response.get(\"status\") == \"done\":\n",
    "            print(f\"- Transcription done. - id: ...{id[-5:]}\")\n",
    "            break\n",
    "        elif poll_response.get(\"status\") == \"error\":\n",
    "            print(f\"- Transcription failed. id: ...{id[-5:]}\")\n",
    "            print(poll_response)\n",
    "        else:\n",
    "            print(f\"Transcription status: {poll_response.get('status')} - id: ...{id[-5:]}\")\n",
    "    \n",
    "        await asyncio.sleep(4)\n",
    "\n",
    "    return poll_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5514788",
   "metadata": {},
   "source": [
    "### Headers and example files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60f5389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/Introducción Master Class.webm'),\n",
       " PosixPath('data/Introducing_ Better Offline.mp3'),\n",
       " PosixPath('data/You need to classify documents before trying to extract data.webm')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"x-gladia-key\": x_gladia_key,\n",
    "}\n",
    "\n",
    "files_path = Path(\"./data\")\n",
    "files_to_upload = [f for f in files_path.iterdir()]\n",
    "files_to_upload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facecd3a",
   "metadata": {},
   "source": [
    "## `asyncio.gather` vs `asyncio.as_completed`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07773d7",
   "metadata": {},
   "source": [
    "As we saw, the process to transcribe audios has the following steps:\n",
    "- Upload audio files\n",
    "- Initiate the transcription job\n",
    "- Awaiting completion of the transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3eec78",
   "metadata": {},
   "source": [
    "### `asyncio.gather`\n",
    "\n",
    "This function orchestrate tasks by leveraging `asuncio.gather()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8157c144",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_function_orchestrator(func: 'function', tasks_param: list):\n",
    "    \"\"\"Gather results from an async function and a list of parameters\n",
    "    \"\"\"\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "\n",
    "        tasks = [\n",
    "            func(session, p) for p in tasks_param\n",
    "        ]\n",
    "\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e80bfb",
   "metadata": {},
   "source": [
    "#### Uploading files asynchronously\n",
    "\n",
    "The first step in the transcription journey involves uploading audio files to Gladia. With asyncio we can simultaneously upload multiple files. With `asyncio.gather()` we can initiate several upload tasks concurrently, allowing our script to move forward without having to wait for each file to finish uploading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8318b17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Uploading file to Gladia...\n",
      "- Uploading file to Gladia...\n",
      "- Uploading file to Gladia...\n",
      "- Request successful\n",
      "Upload Time: 4.77 seconds for `Introducción Master Class.webm`\n",
      "- Request successful\n",
      "Upload Time: 6.14 seconds for `You need to classify documents before trying to extract data.webm`\n",
      "- Request successful\n",
      "Upload Time: 6.86 seconds for `Introducing_ Better Offline.mp3`\n",
      "Total Time: 7.03 seconds\n"
     ]
    }
   ],
   "source": [
    "with catchtime() as t:\n",
    "    upload_results = asyncio.run(\n",
    "        async_function_orchestrator(func=a_upload_file, tasks_param=files_to_upload)\n",
    "    )\n",
    "\n",
    "print(f'Total Time: {t.seconds} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b742348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio_url: https://api.gladia.io/file/5d7d3d23-2de3-4c78-93c8-9010c6d7b6a7\n",
      "filename: data%2FIntroducci%C3%B3n%20Master%20Class\n",
      "id: 5d7d3d23-2de3-4c78-93c8-9010c6d7b6a7\n",
      "\n",
      "audio_url: https://api.gladia.io/file/dee3b9c4-90d4-4b15-8a94-fbd66f11d6e2\n",
      "filename: data%2FIntroducing_%20Better%20Offline\n",
      "id: dee3b9c4-90d4-4b15-8a94-fbd66f11d6e2\n",
      "\n",
      "audio_url: https://api.gladia.io/file/1cf50050-a7c4-4a5b-b99c-f6face16e942\n",
      "filename: data%2FYou%20need%20to%20classify%20documents%20before%20trying%20to%20extract%20data\n",
      "id: 1cf50050-a7c4-4a5b-b99c-f6face16e942\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in upload_results:\n",
    "    print(f\"audio_url: {file['audio_url']}\")\n",
    "    print(f\"filename: {file['audio_metadata']['filename']}\")\n",
    "    print(f\"id: {file['audio_metadata']['id']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2779ce4",
   "metadata": {},
   "source": [
    "#### Asynchronously requesting transcriptions\n",
    "\n",
    "Once files are uploaded, the next step is to request transcriptions. Similar to the upload process, `asyncio.gather()` enables us to send out transcription requests for all uploaded files in parallel. This ensures that we're efficiently moving through or workload without unnecessary delays between requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16011b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Sending transcription request to Gladia API...\n",
      "- Sending transcription request to Gladia API...\n",
      "- Sending transcription request to Gladia API...\n",
      "- Request successful\n",
      "Create Transcription Job: 1.2 seconds for `https://api.gladia.io/file/dee3b9c4-90d4-4b15-8a94-fbd66f11d6e2`\n",
      "- Request successful\n",
      "Create Transcription Job: 1.24 seconds for `https://api.gladia.io/file/1cf50050-a7c4-4a5b-b99c-f6face16e942`\n",
      "- Request successful\n",
      "Create Transcription Job: 1.25 seconds for `https://api.gladia.io/file/5d7d3d23-2de3-4c78-93c8-9010c6d7b6a7`\n",
      "Total Time: 1.25 seconds\n"
     ]
    }
   ],
   "source": [
    "audio_urls = [result[\"audio_url\"] for result in upload_results]\n",
    "\n",
    "with catchtime() as t:\n",
    "    transcription_job_results = asyncio.run(\n",
    "        async_function_orchestrator(a_create_transcription_job, audio_urls)\n",
    "    )\n",
    "\n",
    "print(f'Total Time: {t.seconds} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23c2516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '517ca2e0-7830-4803-a66c-4cb2cb259fd5',\n",
       "  'result_url': 'https://api.gladia.io/v2/transcription/517ca2e0-7830-4803-a66c-4cb2cb259fd5'},\n",
       " {'id': '8a247329-c586-4685-914d-06e3e204f581',\n",
       "  'result_url': 'https://api.gladia.io/v2/transcription/8a247329-c586-4685-914d-06e3e204f581'},\n",
       " {'id': '9c7d8255-a7c3-465e-a0f5-01569ba49f4c',\n",
       "  'result_url': 'https://api.gladia.io/v2/transcription/9c7d8255-a7c3-465e-a0f5-01569ba49f4c'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription_job_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0ab43c",
   "metadata": {},
   "source": [
    "#### Wait for the transcriptions to be ready\n",
    "\n",
    "Same as the uploading and transcription request process, we wait for transcriptions in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c36979b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Request successful\n",
      "Transcription status: queued - id: ...59fd5\n",
      "- Request successful\n",
      "Transcription status: queued - id: ...49f4c\n",
      "- Request successful\n",
      "Transcription status: queued - id: ...4f581\n",
      "- Request successful\n",
      "Transcription status: queued - id: ...59fd5\n",
      "- Request successful\n",
      "Transcription status: processing - id: ...49f4c\n",
      "- Request successful\n",
      "Transcription status: queued - id: ...4f581\n",
      "- Request successful\n",
      "Transcription status: processing - id: ...59fd5\n",
      "- Request successful\n",
      "Transcription status: processing - id: ...49f4c\n",
      "- Request successful\n",
      "Transcription status: processing - id: ...4f581\n",
      "- Request successful\n",
      "Transcription status: processing - id: ...59fd5\n",
      "- Request successful\n",
      "Transcription status: processing - id: ...4f581\n",
      "- Request successful\n",
      "Transcription status: processing - id: ...49f4c\n",
      "- Request successful\n",
      "Transcription status: processing - id: ...59fd5\n",
      "- Request successful\n",
      "Transcription status: processing - id: ...4f581\n",
      "- Request successful\n",
      "- Transcription done. - id: ...49f4c\n",
      "- Request successful\n",
      "- Transcription done. - id: ...59fd5\n",
      "- Request successful\n",
      "Transcription status: processing - id: ...4f581\n",
      "- Request successful\n",
      "- Transcription done. - id: ...4f581\n",
      "Total Time: 28.89 seconds\n"
     ]
    }
   ],
   "source": [
    "with catchtime() as t:\n",
    "    transcription_results = asyncio.run(\n",
    "        async_function_orchestrator(a_wait_until_job_done, transcription_job_results)\n",
    "    )\n",
    "\n",
    "print(f'Total Time: {t.seconds} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d6ea84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "517ca2e0-7830-4803-a66c-4cb2cb259fd5\n",
      "data%2FIntroducci%C3%B3n%20Master%20Class\n",
      "['es']\n",
      "Música ¿Necesitas tutorías en tus tareas escolares? ¿Asesorías en proyectos académicos y empresariales? Aquí está la solución. Ingresa desde tu PC a www.masterclass.com.ec o descarga la aplicación desde tu móvil masterclass-ec. Después, selecciona la\n",
      "...\n",
      " tutorías recibidas, recibe una gratis. Recuerda que nuestra plataforma es inclusiva. Si necesitas que la tutoría vaya acompañada de un intérprete de lengua de señas ecuatoriana, escoge la opción Intérprete. Masterclass. El conocimiento a tu alcance.\n",
      "\n",
      "8a247329-c586-4685-914d-06e3e204f581\n",
      "data%2FIntroducing_%20Better%20Offline\n",
      "['en']\n",
      "Hi, I'm Ed Zitron, host of the Better Offline podcast on the Cool Zone Media Network. I've been both a tech writer and a tech executive for the last 15 years, and I've seen this industry grow from a bunch of dorks building things in their garage into\n",
      "...\n",
      "no bullshit, just a crystal clear window into a world that quietly finds new and innovative ways to make billionaires rich. Listen to Better Offline on the iHeartRadio app, Apple Podcasts, or wherever else you get your podcasts. Thanks for listening.\n",
      "\n",
      "9c7d8255-a7c3-465e-a0f5-01569ba49f4c\n",
      "data%2FYou%20need%20to%20classify%20documents%20before%20trying%20to%20extract%20data\n",
      "['en']\n",
      "Today I've been talking to a bunch of people on doing document extraction. And in particular, I think a lot of people who are coming into this world with that much machine learning experience kind of think that AGI is here and they think that Jupyter\n",
      "...\n",
      "y valuable. You might have to be in a world where you pay humans to do this relabeling. Because we have before, if you're wrong in your pre-work, it's very easy to not lose all that effort. And you can just rebuild a lot of these indices very easily.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for transcription in transcription_results:\n",
    "    print(transcription[\"id\"])\n",
    "    print(transcription[\"file\"][\"filename\"])\n",
    "    print(transcription[\"result\"][\"transcription\"][\"languages\"])\n",
    "    print(transcription[\"result\"][\"transcription\"][\"full_transcript\"][:250])\n",
    "    print(\"...\")\n",
    "    print(transcription[\"result\"][\"transcription\"][\"full_transcript\"][-250:])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022fb3b0",
   "metadata": {},
   "source": [
    "### `asyncio.as_completed`\n",
    "\n",
    "Finally, instead of waiting for each step to finish, we can adopt a different strategy by processing the files as they are uploaded. Then, using `asyncio.as_completed()` allow us to process the end result as each transcription process ends.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3644a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def a_upload_and_process(\n",
    "    session: aiohttp.client.ClientSession, \n",
    "    file_path: Path\n",
    ") -> dict:\n",
    "    \"\"\"Upload and process the file\n",
    "    \"\"\"\n",
    "    # Upload the file\n",
    "    uploaded = await a_upload_file(session, file_path)\n",
    "    \n",
    "    audio_url = uploaded[\"audio_url\"]\n",
    "    \n",
    "    # Start the transcription\n",
    "    transcription_job_result = await a_create_transcription_job(session, audio_url)\n",
    "    \n",
    "    # Wait for the transcription to complete\n",
    "    transcription_result = await a_wait_until_job_done(session, transcription_job_result)\n",
    "    \n",
    "    return transcription_result\n",
    "\n",
    "\n",
    "async def async_tasks_orchestrator(files_to_upload: List[Path]) -> None:\n",
    "    \"\"\"Process transcriptions as they complete\n",
    "    \"\"\"\n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        \n",
    "        transcription_tasks = [\n",
    "            a_upload_and_process(session, file) for file in files_to_upload\n",
    "        ]\n",
    "        \n",
    "        for transcription_task in asyncio.as_completed(transcription_tasks):\n",
    "            \n",
    "            transcription = await transcription_task\n",
    "            process_transcription(transcription)\n",
    "            #yield transcription\n",
    "\n",
    "\n",
    "def process_transcription(transcription: dict) -> None:\n",
    "    print(f\"<<<<<Transcription with id: {transcription['id']} Done>>>>>\")\n",
    "    print(transcription[\"file\"][\"filename\"])\n",
    "    print(transcription[\"result\"][\"transcription\"][\"languages\"])\n",
    "    print(transcription[\"result\"][\"transcription\"][\"full_transcript\"][:250])\n",
    "    print(\"...\")\n",
    "    print(transcription[\"result\"][\"transcription\"][\"full_transcript\"][-250:])\n",
    "    print(\"<<<<</Transcription Done>>>>>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4096b2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Uploading file to Gladia...\n",
      "- Uploading file to Gladia...\n",
      "- Uploading file to Gladia...\n",
      "- Request successful\n",
      "Upload Time: 3.56 seconds for `Introducción Master Class.webm`\n",
      "- Sending transcription request to Gladia API...\n",
      "- Request successful\n",
      "Create Transcription Job: 0.35 seconds for `https://api.gladia.io/file/799bac2b-8217-49a1-a67c-c53966fb9b60`\n",
      "- Request successful\n",
      "Transcription status: queued - id: ...1fba0\n",
      "- Request successful\n",
      "Upload Time: 4.28 seconds for `Introducing_ Better Offline.mp3`\n",
      "- Sending transcription request to Gladia API...\n",
      "- Request successful\n",
      "Upload Time: 4.4 seconds for `You need to classify documents before trying to extract data.webm`\n",
      "- Sending transcription request to Gladia API...\n",
      "- Request successful\n",
      "Create Transcription Job: 0.47 seconds for `https://api.gladia.io/file/dd94ecad-ec21-40e7-97fd-ecd063afd686`\n",
      "- Request successful\n",
      "Create Transcription Job: 0.43 seconds for `https://api.gladia.io/file/47ae9c16-665c-46f8-8379-0ae38f81eb01`\n",
      "- Request successful\n",
      "Transcription status: queued - id: ...c17fb\n",
      "- Request successful\n",
      "Transcription status: queued - id: ...89830\n",
      "- Request successful\n",
      "Transcription status: processing - id: ...1fba0\n",
      "- Request successful\n",
      "Transcription status: queued - id: ...c17fb\n",
      "- Request successful\n",
      "Transcription status: queued - id: ...89830\n",
      "- Request successful\n",
      "Transcription status: processing - id: ...1fba0\n",
      "- Request successful\n",
      "Transcription status: queued - id: ...c17fb\n",
      "- Request successful\n",
      "Transcription status: queued - id: ...89830\n",
      "- Request successful\n",
      "- Transcription done. - id: ...1fba0\n",
      "<<<<<Transcription with id: 145b8844-c360-406f-8bb9-2de82661fba0 Done>>>>>\n",
      "data%2FIntroducci%C3%B3n%20Master%20Class\n",
      "['es']\n",
      "Música ¿Necesitas tutorías en tus tareas escolares? ¿Asesorías en proyectos académicos y empresariales? Aquí está la solución. Ingresa desde tu PC a www.masterclass.com.ec o descarga la aplicación desde tu móvil masterclass-ec. Después, selecciona la\n",
      "...\n",
      " tutorías recibidas, recibe una gratis. Recuerda que nuestra plataforma es inclusiva. Si necesitas que la tutoría vaya acompañada de un intérprete de lengua de señas ecuatoriana, escoge la opción Intérprete. Masterclass. El conocimiento a tu alcance.\n",
      "<<<<</Transcription Done>>>>>\n",
      "- Request successful\n",
      "Transcription status: queued - id: ...c17fb\n",
      "- Request successful\n",
      "Transcription status: processing - id: ...89830\n",
      "- Request successful\n",
      "Transcription status: queued - id: ...89830\n",
      "- Request successful\n",
      "Transcription status: processing - id: ...c17fb\n",
      "- Request successful\n",
      "Transcription status: processing - id: ...89830\n",
      "- Request successful\n",
      "Transcription status: processing - id: ...c17fb\n",
      "- Request successful\n",
      "Transcription status: processing - id: ...89830\n",
      "- Request successful\n",
      "Transcription status: processing - id: ...c17fb\n",
      "- Request successful\n",
      "Transcription status: processing - id: ...89830\n",
      "- Request successful\n",
      "Transcription status: processing - id: ...c17fb\n",
      "- Request successful\n",
      "Transcription status: processing - id: ...89830\n",
      "- Request successful\n",
      "- Transcription done. - id: ...c17fb\n",
      "<<<<<Transcription with id: 8f880055-b56f-4297-8390-5d7668ec17fb Done>>>>>\n",
      "data%2FIntroducing_%20Better%20Offline\n",
      "['en']\n",
      "Hi, I'm Ed Zitron, host of the Better Offline podcast on the Cool Zone Media Network. I've been both a tech writer and a tech executive for the last 15 years, and I've seen this industry grow from a bunch of dorks building things in their garage into\n",
      "...\n",
      "no bullshit, just a crystal clear window into a world that quietly finds new and innovative ways to make billionaires rich. Listen to Better Offline on the iHeartRadio app, Apple Podcasts, or wherever else you get your podcasts. Thanks for listening.\n",
      "<<<<</Transcription Done>>>>>\n",
      "- Request successful\n",
      "- Transcription done. - id: ...89830\n",
      "<<<<<Transcription with id: 9b13aff2-aa31-4d90-8e9d-dfab9ff89830 Done>>>>>\n",
      "data%2FYou%20need%20to%20classify%20documents%20before%20trying%20to%20extract%20data\n",
      "['en']\n",
      "Today I've been talking to a bunch of people on doing document extraction. And in particular, I think a lot of people who are coming into this world with that much machine learning experience kind of think that AGI is here and they think that Jupyter\n",
      "...\n",
      "y valuable. You might have to be in a world where you pay humans to do this relabeling. Because we have before, if you're wrong in your pre-work, it's very easy to not lose all that effort. And you can just rebuild a lot of these indices very easily.\n",
      "<<<<</Transcription Done>>>>>\n",
      "Total Time: 44.65 seconds\n"
     ]
    }
   ],
   "source": [
    "with catchtime() as t:\n",
    "    transcription_job_results = asyncio.run(\n",
    "        async_tasks_orchestrator(files_to_upload)\n",
    "    )\n",
    "\n",
    "print(f'Total Time: {t.seconds} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daad941",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "Processing times will depend on Gladia response time. In this example we cannot directly compare `asyncio.gather()` with `asyncio.as_completed()` without taking into account the time it takes to Gladia to complete each transcription.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb62f0f6",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Integrating Gladia transcription service with Python's asyncio presents a powerful approach to managing audio data processing tasks efficiently. By utilizing `asyncio.gather()` for parallel uploads, requests and waits; or using `asyncio.as_completed()` and inmediate processing of each uploaded file, we significantly enhance the speed and responsiveness of the process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
