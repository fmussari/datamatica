{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a27ede8",
   "metadata": {},
   "source": [
    "---\n",
    "title: RAG on Microsoft Learning Paths - Part 2. Embeddings  \n",
    "author: \"Francisco Mussari\"  \n",
    "date: 2023-12-05  \n",
    "image: \"\"  \n",
    "categories: [RAG, LLM, Embeddings, SQLAlchemy, PostgreSQL, Supabase, pgvector, Vector Search]  \n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    toc-depth: 3\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23a1d1e",
   "metadata": {},
   "source": [
    "We've successfully stored our contextual data in a free Supabase instance. Our next step is to evaluate how LLMs perform on Power BI Learning Path questions. In this post, we are going to create embeddings for both questions and contexts.  \n",
    "  \n",
    "**The Need for a Vector Database:**  \n",
    "  \n",
    "PostgreSQL offers an open-source extension called pgvector that allows efficient storage and similarity searches for vectors. However, our existing database schema requires careful consideration for embedding insertion. While the llamaindex solution creates a defined schema using `SupabaseVectorStore`, we'll opt for `vecs`, a Python client designed to manage and query vector stores in PostgreSQL as an simplified abstraction above `pgvector`.  \n",
    "  \n",
    "**Part 2 Goals:**  \n",
    "  \n",
    "- Read Data: We'll retrieve the scraped content stored within Supabase (PostgreSQL).\n",
    "- Embed Everything: We'll create embeddings for contextual content, questions, and questions with their possible answers.\n",
    "- Store Embeddings: We'll store the generated embeddings and metadata back in Supabase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d910a5",
   "metadata": {},
   "source": [
    "## References\n",
    "- [RAG on Microsoft Learning Paths - Part 1. Web Scraping and Supabase](./RAG_on_Microsoft_Learning_Paths_-_Part_1.ipynb)\n",
    "- [vecs](https://github.com/supabase/vecs/blob/main/README.md)\n",
    "- [jina_embeddings.ipynb](https://github.com/run-llama/llama_index/blob/main/docs/examples/embeddings/jina_embeddings.ipynb)\n",
    "- [Using SQLAlchemy ORM with existing tables](https://sanjayasubedi.com.np/python/sqlalchemy/using-sqlalchemy-orm-with-existing-tables/)\n",
    "- [How to query JSONB, beginner sheet cheat](https://medium.com/hackernoon/how-to-query-jsonb-beginner-sheet-cheat-4da3aa5082a3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de6f63c",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bc0d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vecs\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Tuple\n",
    "\n",
    "from llama_index.embeddings import HuggingFaceEmbedding\n",
    "from llama_index import ServiceContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1382a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9.11.post1\n",
      "4.35.2\n"
     ]
    }
   ],
   "source": [
    "import llama_index\n",
    "print(llama_index.__version__)\n",
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d2158f",
   "metadata": {},
   "source": [
    "## Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e52220",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import userdata\n",
    "    IS_COLAB = True\n",
    "    supabase_host = userdata.get(\"SUPABASE_HOST\")\n",
    "    supabase_pass = userdata.get(\"SUPABASE_PASS\")\n",
    "else:\n",
    "    load_dotenv()\n",
    "    supabase_host = os.environ.get('SUPABASE_HOST')\n",
    "    supabase_pass = os.environ.get('SUPABASE_PASS')\n",
    "\n",
    "DB_CONNECTION = f\"postgresql://postgres:{supabase_pass}@{supabase_host}:5432/postgres\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7551340",
   "metadata": {},
   "source": [
    "## Embedding Models\n",
    "\n",
    "This work leverages Jina AI's \"worldâ€™s first open-source 8K text embedding model\". While testing on my 8GB GPU model, I encountered memory limitations when the context exceeded 2,500 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5917b63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_models = {\n",
    "    \"jinaai/jina-embeddings-v2-small-en\":\n",
    "        {\"size\":  512, \"collection\": None, \"table\": None, \"embed_model\": None},\n",
    "    \"jinaai/jina-embeddings-v2-base-en\":\n",
    "        {\"size\": 768, \"collection\": None, \"table\": None, \"embed_model\": None},\n",
    "    #\"jinaai/jina-embeddings-v2-large-en\":\n",
    "        #{\"size\": 2048, \"collection\": None, \"table\": None, \"embed_model\": None},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f10f33",
   "metadata": {},
   "source": [
    "## Create tables and collections to store embeddings using `vecs`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0547ace4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vx = vecs.create_client(DB_CONNECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6032f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _model in emb_models.keys():\n",
    "    _data = emb_models[_model]\n",
    "    _data[\"table\"] = _model.split(\"/\")[-1].replace(\"-\", \"_\").replace(\".\", \"_\")\n",
    "    _data[\"collection\"] = vx.get_or_create_collection(name=_data[\"table\"], dimension=_data[\"size\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95279ab5",
   "metadata": {},
   "source": [
    "## Get Content from Database\n",
    "Let's get the content we scraped in Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7270529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine.row import Row\n",
    "from sqlalchemy.engine.result import RMKeyView\n",
    "\n",
    "from sqlalchemy import select, text, func, and_, literal_column, cast, String"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86e42ba",
   "metadata": {},
   "source": [
    "### Connect to existing tables\n",
    "This is the model we created in Part 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fc3420",
   "metadata": {},
   "source": [
    "<img src=\"ERD.svg\" align=\"center\"/>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9bb6ff",
   "metadata": {},
   "source": [
    "Fig 1. Model's ERD. (Created with https://dbdiagram.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ce1e42",
   "metadata": {},
   "source": [
    "### Create connections to existing tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c068cb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_275/1542308513.py:4: SAWarning: Did not recognize type 'vector' of column 'embedding'\n",
      "  Base.prepare(autoload_with=engine)\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine(DB_CONNECTION)\n",
    "\n",
    "Base = automap_base()\n",
    "Base.prepare(autoload_with=engine)\n",
    "\n",
    "# matching that of the table name.\n",
    "Exam = Base.classes.exam\n",
    "Learning = Base.classes.learning_path\n",
    "Module = Base.classes.module\n",
    "Chapter = Base.classes.chapter\n",
    "Question = Base.classes.question\n",
    "Answer = Base.classes.answer\n",
    "\n",
    "session = Session(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66b2a1b",
   "metadata": {},
   "source": [
    "### Three ways to query the database with SQLAlchemy\n",
    "Before we continue, let's explore some ways we can query the database.\n",
    "#### 1. Using `select`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f63ac6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMKeyView(['id', 'question', 'chapter_id'])\n",
      "Which data role enables advanced analytics capabilities specifically through reports and visualizations?\n",
      "Which data analyst task has a critical performance impact on reporting and data analysis?\n"
     ]
    }
   ],
   "source": [
    "stmt = select(Question).where(Question.id <= 2)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(stmt)\n",
    "    print(result.keys())\n",
    "    for row in result:\n",
    "        print(row.question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfa10a5",
   "metadata": {},
   "source": [
    "#### 2. Creating a SQL statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecab90a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "SELECT  ex.id AS exam_id, pa.id AS path_id, mo.id AS module_id, \n",
    "        ch.id AS chapter_id, ch.is_check\n",
    "FROM exam AS ex JOIN learning_path AS pa ON ex.id=pa.exam_id\n",
    "JOIN module AS mo ON pa.id=mo.path_id\n",
    "JOIN chapter AS ch ON mo.id=ch.module_id\n",
    "WHERE NOT ch.is_check\n",
    "LIMIT 5\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e85b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMKeyView(['exam_id', 'path_id', 'module_id', 'chapter_id', 'is_check'])\n",
      "(1, 1, 1, 1, False)\n",
      "(1, 1, 1, 2, False)\n",
      "(1, 1, 1, 3, False)\n",
      "(1, 1, 1, 4, False)\n",
      "(1, 1, 1, 6, False)\n"
     ]
    }
   ],
   "source": [
    "stmt = text(q)\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(stmt)\n",
    "    print(result.keys())\n",
    "    for row in result:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8595a74",
   "metadata": {},
   "source": [
    "#### 3. Using `session.query`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3765009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1, 1, 1, False),\n",
       " (1, 1, 1, 2, False),\n",
       " (1, 1, 1, 3, False),\n",
       " (1, 1, 1, 4, False),\n",
       " (1, 1, 1, 6, False)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = (session.query(\n",
    "        Exam.id, Learning.id, Module.id, Chapter.id, Chapter.is_check)\n",
    "     .join(Learning, Exam.id==Learning.exam_id)\n",
    "     .join(Module, Learning.id==Module.path_id)\n",
    "     .join(Chapter, Module.id==Chapter.module_id)\n",
    "     .where(~Chapter.is_check)\n",
    "     .limit(5))\n",
    "[r for r in q]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0cd235",
   "metadata": {},
   "source": [
    "### Remove unwanted parts in content\n",
    "There are links to images we don't need to embed, lets remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82379fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a data analyst, you are on a journey. Think about all the data that is\n",
      "being generated each day and that is available in an organization, from\n",
      "transactional data in a traditional database, telemetry data from services\n",
      "that you use, to signals that you get from different areas like social media.\n",
      "\n",
      "[![abundance of data](media/abundance-data-ss.png)](media/abundance-data-\n",
      "ss.png#lightbox)\n",
      "\n",
      "For example, today's retail businesses collect and store massive amounts of\n",
      "data that track the items you br\n"
     ]
    }
   ],
   "source": [
    "stmt = select(Chapter.content).where(Chapter.id == 1)\n",
    "with engine.connect() as conn:\n",
    "    for row in conn.execute(stmt):\n",
    "        text = row.content\n",
    "\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b7a1d4",
   "metadata": {},
   "source": [
    "Let's filter the patterns like:  \n",
    "\n",
    "- `[![abundance of data](media/abundance-data-ss.png)](media/abundance-data-\n",
    "ss.png#lightbox)`  \n",
    "  \n",
    "- `![Screenshot of the filtered Top 100 Contributors report page](media/pbi-\n",
    "touring_05.png)`\n",
    "\n",
    "Which represents images in the content and doesn't add any value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c358f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_content_image(text: str):\n",
    "    #text = re.sub(\"\\[\\!\\[[\\s\\S]*\\)\\]\\([\\s\\S]*\\)\\n\\n\", \"\", text)\n",
    "    better_regex = r\"\\[{0,1}\\!\\[[\\s\\S]*?\\)$\\n{0,2}\"\n",
    "    return re.sub(\"\\[{0,1}\\!\\[[\\s\\S]*?\\)\\n\\n\", \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4569f763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a data analyst, you are on a journey. Think about all the data that is\n",
      "being generated each day and that is available in an organization, from\n",
      "transactional data in a traditional database, telemetry data from services\n",
      "that you use, to signals that you get from different areas like social media.\n",
      "\n",
      "For example, today's retail businesses collect and store massive amounts of\n",
      "data that track the items you br\n"
     ]
    }
   ],
   "source": [
    "print(remove_content_image(text[:500]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bb6bbc",
   "metadata": {},
   "source": [
    "## Populate the database with the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415c21db",
   "metadata": {},
   "source": [
    "### 1. Chapter Content (excluding questions and/or answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b797c1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_cols = [\"exam_id\", \"path_id\", \"module_id\", \"chapter_id\", \"content\"]\n",
    "\n",
    "content_stmt = (\n",
    "    select(\n",
    "        Exam.id.label(content_cols[0]),\n",
    "        Learning.id.label(content_cols[1]),\n",
    "        Module.id.label(content_cols[2]),\n",
    "        Chapter.id.label(content_cols[3]),\n",
    "        Chapter.content.label(content_cols[4])\n",
    "    )\n",
    "    .join(Learning, Exam.id==Learning.exam_id)\n",
    "    .join(Module, Learning.id==Module.path_id)\n",
    "    .join(Chapter, Module.id==Chapter.module_id)\n",
    "    .where(~Chapter.is_check)\n",
    "    #.where(and_(Chapter.id<=80, Chapter.id>=75)) # testing porpuses\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f79930d",
   "metadata": {},
   "source": [
    "### 2. Questions' Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbb692c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_cols = [\"exam_id\", \"path_id\", \"module_id\", \"chapter_id\", \"question_id\", \"content\"]\n",
    "\n",
    "questions_stmt = (\n",
    "    select(\n",
    "        Exam.id.label(question_cols[0]),\n",
    "        Learning.id.label(question_cols[1]),\n",
    "        Module.id.label(question_cols[2]),\n",
    "        Chapter.id.label(question_cols[3]),\n",
    "        Question.id.label(question_cols[4]),\n",
    "        Question.question.label(question_cols[5])\n",
    "    )\n",
    "    .join(Learning, Exam.id==Learning.exam_id)\n",
    "    .join(Module, Learning.id==Module.path_id)\n",
    "    .join(Chapter, Module.id==Chapter.module_id)\n",
    "    .join(Question, Chapter.id==Question.chapter_id)\n",
    "    .where(Chapter.is_check)\n",
    "    #.where(and_(Chapter.id<=80, Chapter.id>=75)) # testing porpuses\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0639e2",
   "metadata": {},
   "source": [
    "#### How does the query behaves (testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d373391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMKeyView(['exam_id', 'path_id', 'module_id', 'chapter_id', 'question_id', 'content'])\n",
      "(1, 3, 10, 80, 29, 'Which statement about calculated tables is true?')\n",
      "(1, 3, 10, 80, 30, 'Which statement about calculated columns is true?')\n",
      "(1, 3, 10, 80, 31, \"You're developing a Power BI desktop model that sources data from an Excel workbook. The workbook has an employee table that stores one row for each  ... (181 characters truncated) ... ze payroll data within the organization hierarchy (like, executive level, manager level, and so on). Which technique will you use to add the columns?\")\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as conn:\n",
    "    results = conn.execute(questions_stmt)\n",
    "    result_keys = results.keys()\n",
    "    print(result_keys)\n",
    "    for row in results:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11756d37",
   "metadata": {},
   "source": [
    "### 3. Questions' + Answers' Embeddings\n",
    "I wanted to also embed question with its possible answers to check whether this could possibly translate in better retrievals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a2293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_cols = [\n",
    "    \"exam_id\", \"path_id\", \"module_id\", \"chapter_id\", \n",
    "    \"question_id\", \"answers_count\", \"content\"]\n",
    "\n",
    "qa_stmt = (\n",
    "    select(\n",
    "        Exam.id.label(qa_cols[0]),               # exam_id\n",
    "        Learning.id.label(qa_cols[1]),           # path_id\n",
    "        Module.id.label(qa_cols[2]),             # module_id\n",
    "        Chapter.id.label(qa_cols[3]),            # chapter_id\n",
    "        Question.id.label(qa_cols[4]),           # question_id\n",
    "        func.count(Answer.id).label(qa_cols[5]), # answers_count\n",
    "        #func.string_agg(cast(Answer.id, String), literal_column(\"','\")),\n",
    "        func.concat(\n",
    "            func.string_agg(\n",
    "                Question.question.distinct(), literal_column(\"''\")\n",
    "            ), \n",
    "            \": \\n- \",\n",
    "            func.string_agg(Answer.answer, literal_column(\"'\\n- '\"))\n",
    "        ).label(qa_cols[6]),                     # content\n",
    "    )\n",
    "    .join(Learning, Exam.id==Learning.exam_id)\n",
    "    .join(Module, Learning.id==Module.path_id)\n",
    "    .join(Chapter, Module.id==Chapter.module_id)\n",
    "    .join(Question, Chapter.id==Question.chapter_id)\n",
    "    .join(Answer, Question.id==Answer.question_id)\n",
    "    \n",
    "    .where(Chapter.is_check)\n",
    "    #.where(and_(Chapter.id<=80, Chapter.id>=75)) # testing porpuses\n",
    "    .group_by(Exam.id, Learning.id, Module.id, Chapter.id, Question.id)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169276ca",
   "metadata": {},
   "source": [
    "#### How does the query behaves (testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2dfe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMKeyView(['exam_id', 'path_id', 'module_id', 'chapter_id', 'question_id', 'answers_count', 'content'])\n",
      "29 4 Which statement about calculated tables is true?: \n",
      "- Calculated tables increase the size of the semantic model.\n",
      "- Calculated tables are evaluated by using row context.\n",
      "- Calculated tables are created in Power Query.\n",
      "- Calculated tables cannot include calculated columns.\n",
      "30 4 Which statement about calculated columns is true?: \n",
      "- Calculated columns are created in the Power Query Editor window.\n",
      "- Calculated column formulas are evaluated by using row context.\n",
      "- Calculated column formulas can only reference columns from within their table.\n",
      "- Calculated columns can't be related to non-calculated columns.\n",
      "31 4 You're developing a Power BI desktop model that sources data from an Excel workbook. The workbook has an employee table that stores one row for each employee. Each row has a reference to the employee's manager, which is also a row in the employee table. You need to add several columns to the Employee table in your model to analyze payroll data within the organization hierarchy (like, executive level, manager level, and so on). Which technique will you use to add the columns?: \n",
      "- Add persisted columns to a table by using T-SQL.\n",
      "- Add column expressions in a view by using T-SQL.\n",
      "- Add computed columns by using M.\n",
      "- Add calculated columns by using DAX.\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as conn:\n",
    "    results = conn.execute(qa_stmt)\n",
    "    result_keys = results.keys()\n",
    "    print(result_keys)\n",
    "    for row in results:\n",
    "        print(row.question_id, row.answers_count, row.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e840c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stmts = [content_stmt, questions_stmt, qa_stmt]\n",
    "cols_lst = [content_cols, question_cols, qa_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58fd008",
   "metadata": {},
   "source": [
    "### Function to upsert embeddings and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce68b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_results(\n",
    "    embed_model: HuggingFaceEmbedding, \n",
    "    results: List[Row],\n",
    "    result_keys: RMKeyView,\n",
    "    collection: vecs.Collection\n",
    "):    \n",
    "    for i, row in enumerate(results):\n",
    "    \n",
    "        content = remove_content_image(row[-1]).replace(\"\\n\\n\", \"\\n\")\n",
    "        \n",
    "        number_of_words = len(content.split())\n",
    "        metadata = {col: row[idx] for idx, col in enumerate(list(result_keys)[:-1])}\n",
    "        \n",
    "        metadata['question_id'] = metadata.get('question_id', None) or 0\n",
    "        metadata['answers_count'] = metadata.get('answers_count', None) or 0\n",
    "        metadata['is_check'] = bool(metadata['question_id'])\n",
    "        metadata['has_answers'] = bool(metadata['answers_count'])\n",
    "        \n",
    "        metadata['number_of_words'] = number_of_words\n",
    "        \n",
    "        id = \"-\".join([f\"{r:03d}\" for r in row[:4]])\n",
    "        id += f\"-{metadata['question_id']:03d}\" \n",
    "        id += f\"-{metadata['has_answers']:01d}\"\n",
    "        \n",
    "        #print(id)\n",
    "        #metadata['content'] = content\n",
    "        \n",
    "        q_embedding = (embed_model.get_query_embedding(content))\n",
    "        collection.upsert(\n",
    "            records=[(id, q_embedding, metadata)]\n",
    "        )\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"{i+1} rows upserted to collection {collection.name}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd7c686",
   "metadata": {},
   "source": [
    "### For each model and content type, call the previous function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0061ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embed model:\n",
      "jinaai/jina-embeddings-v2-small-en\n",
      "\n",
      "173 rows upserted to collection jina_embeddings_v2_small_en.\n",
      "69 rows upserted to collection jina_embeddings_v2_small_en.\n",
      "69 rows upserted to collection jina_embeddings_v2_small_en.\n",
      "\n",
      "Embed model:\n",
      "jinaai/jina-embeddings-v2-base-en\n",
      "\n",
      "173 rows upserted to collection jina_embeddings_v2_base_en.\n",
      "69 rows upserted to collection jina_embeddings_v2_base_en.\n",
      "69 rows upserted to collection jina_embeddings_v2_base_en.\n"
     ]
    }
   ],
   "source": [
    "for _model in emb_models.keys():\n",
    "    \n",
    "    embed_model = HuggingFaceEmbedding(\n",
    "        model_name=_model, trust_remote_code=True,\n",
    "        #device=\"cpu\"\n",
    "    )\n",
    "    \n",
    "    print()\n",
    "    print(f\"Embed model:\\n{_model}\")\n",
    "    print()\n",
    "    for stmt in stmts:\n",
    "        with engine.connect() as conn:\n",
    "            results = conn.execute(stmt)\n",
    "            result_keys = results.keys()\n",
    "            results = [row for row in results]\n",
    "\n",
    "        collection = emb_models[_model][\"collection\"]\n",
    "        embed_results(embed_model, results, result_keys, collection)\n",
    "    \n",
    "    embed_model = None\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df69578",
   "metadata": {},
   "source": [
    "## Exploring the Embeddings and content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d52f4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_275/4242081468.py:4: SAWarning: Did not recognize type 'vector' of column 'vec'\n",
      "  VecsBase.prepare(autoload_with=engine, schema=\"vecs\")\n"
     ]
    }
   ],
   "source": [
    "emb_table = emb_models[_model]['table']\n",
    "\n",
    "VecsBase = automap_base()\n",
    "VecsBase.prepare(autoload_with=engine, schema=\"vecs\")\n",
    "\n",
    "EmbTable = VecsBase.classes[emb_table]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244d8169",
   "metadata": {},
   "source": [
    "### Embeddings for the first question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f00edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMKeyView(['anon_1', 'metadata', 'embedding'])\n"
     ]
    }
   ],
   "source": [
    "stmt = (\n",
    "    select(\n",
    "        cast(EmbTable.metadata['is_check'], String)\n",
    "        , EmbTable.metadata\n",
    "        , EmbTable.vec.label('embedding')\n",
    "    ).where(EmbTable.metadata['is_check'].astext == 'true')\n",
    "    ).limit(1)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    results = conn.execute(stmt)\n",
    "    print(results.keys())\n",
    "    for row in results:\n",
    "        embedding = json.loads(row.embedding)\n",
    "        metadata = row.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084f34ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size: 768\n",
      "First 5 dimensions: [0.0017405826, -0.066035606, 0.023444103, -0.028299995, 9.624907e-06]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Embedding size: {len(embedding)}\")\n",
    "print(f\"First 5 dimensions: {embedding[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d16ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exam_id': 1, 'path_id': 1, 'is_check': True, 'module_id': 1, 'chapter_id': 5, 'has_answers': False, 'question_id': 1, 'answers_count': 0, 'number_of_words': 12}\n"
     ]
    }
   ],
   "source": [
    "print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db82158c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which data role enables advanced analytics capabilities specifically through reports and visualizations?'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = (session.query(\n",
    "        Question.question)\n",
    "     .where(Question.id==metadata['question_id']))\n",
    "\n",
    "[r for r in q][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5750629e",
   "metadata": {},
   "source": [
    "As shown in the metadata, the question belongs to the first module. So the ideal retrieval would get chapters of the first module. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefb5304",
   "metadata": {},
   "source": [
    "### Vector similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0af59aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = collection.query(\n",
    "    data=embedding,\n",
    "    limit=4,\n",
    "    filters={\"question_id\": {\"$eq\": 0}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8e6ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['001-003-009-075-000-0',\n",
       " '001-001-002-012-000-0',\n",
       " '001-004-018-151-000-0',\n",
       " '001-005-023-196-000-0']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b81cb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 12), (9, 75), (18, 151), (23, 196)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = session.query(\n",
    "        EmbTable.metadata['module_id']\n",
    "        , EmbTable.metadata['chapter_id']\n",
    "    ).where(EmbTable.id.in_(ids))\n",
    "\n",
    "module_ids = [r for r in q]\n",
    "module_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafaa515",
   "metadata": {},
   "source": [
    "For the first question, the vector search is returning content from module 2, 9, 18, 23, but not from module 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8302c24",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bccf0dd",
   "metadata": {},
   "source": [
    "- Leveraging a free Supabase instance for storing content and embeddings proved very useful.\n",
    "- Testing additional embedding models like OpenAI's would be valuable, only if it was available in Venezuela.\n",
    "- Part 3 will evaluate retrieval by vector similarity, aiming for question proximity to related content in the vector space."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
