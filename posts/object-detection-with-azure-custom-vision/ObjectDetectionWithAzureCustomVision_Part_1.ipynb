{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50da3568",
   "metadata": {},
   "source": [
    "---\n",
    "title: Telecom Equipment Detection with Azure Custom Vision - Part 1  \n",
    "author: \"Francisco Mussari\"  \n",
    "date: 2022-10-08  \n",
    "categories: [computer-vision, deeplearning, azure, custom-vision, object-detection]  \n",
    "\n",
    "---\n",
    "\n",
    "Building an Object Detection with Azure Custom Vision - Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe690db",
   "metadata": {},
   "source": [
    "![](test-url-Iteration2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5d256b",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef298bd",
   "metadata": {},
   "source": [
    "In this series of post we are going to follow along the process and code required to train an *object detection* model using [Azure Custom Vision](https://azure.microsoft.com/en-us/pricing/details/cognitive-services/custom-vision-service) (in its free tier. \n",
    "\n",
    "We are going to use real world pictures compiled from work I have done over the years in Venezuela. For this *supervised learning* problem we need to tagged images. So we will use [Smart Labeler](https://learn.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/suggested-tags) to do that.\n",
    "\n",
    "After the model is published in Azure service, we can use the API to build and share a demo with [Gradio](https://gradio.app/) and [Huggingface](https://huggingface.co/).\n",
    "\n",
    "Here is the one that is already published for you to test:  \n",
    "https://huggingface.co/spaces/fmussari/Telecom-Object-Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b636cfef",
   "metadata": {},
   "source": [
    "The objects the model will be trained to detect are the following:\n",
    "- Grid Antenna\n",
    "- Panel antenna\n",
    "- Radome antenna\n",
    "- RRU\n",
    "- Shroud antenna\n",
    "- Solid antenna"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bee8f626",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td> <img src=\"images/Grid.jpg\"  alt=\"1\" width = 200px height = 200px ></td>\n",
    "        <td><img src=\"images/Panel.jpg\" alt=\"2\" width = 200px height = 200px></td>\n",
    "        <td><img src=\"images/Radome.jpg\" alt=\"2\" width = 200px height = 200px></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Grid</td><td>Panel</td><td>Radome</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> <img src=\"images/RRU.jpg\"  alt=\"1\" width = 200px height = 200px ></td>\n",
    "        <td> <img src=\"images/Shroud.jpg\"  alt=\"1\" width = 200px height = 200px ></td>\n",
    "        <td> <img src=\"images/Solid.jpg\"  alt=\"1\" width = 200px height = 200px ></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>RRU</td><td>Shroud</td><td>Solid</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dd68e2",
   "metadata": {},
   "source": [
    "## Tutorial Parts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cca633",
   "metadata": {},
   "source": [
    "- Part 1 will cover:\n",
    "    - Creating a [free](https://azure.microsoft.com/en-us/pricing/details/cognitive-services/custom-vision-service/#pricing) Azure [Custom Vision](https://www.customvision.ai/) Service.\n",
    "    - Uploading the images to the service.\n",
    "    - Analyzing what happens to the images after uploading.\n",
    "  \n",
    "- Part 2 will cover:\n",
    "    - How to label the images using [Smart Labeler](https://learn.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/suggested-tags)\n",
    "    - Training and publishing the model.\n",
    "   \n",
    "- Part 3 will cover:\n",
    "    - Create a Huggingface Gradio Demo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2691db76",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Microsoft Learn Excersice: [Detect Objects in Images with Custom Vision](https://microsoftlearning.github.io/AI-102-AIEngineer/Instructions/18-object-detection.html)\n",
    "- Custom Vision Documentation: [Quickstart: Create an object detection project with the Custom Vision client library](https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/quickstarts/object-detection?tabs=visual-studio&pivots=programming-language-python)\n",
    "- REST API Endpoint: [Custom Vision REST API reference - Azure Cognitive Services](https://docs.microsoft.com/en-us/rest/api/custom-vision/)\n",
    "- APIs Documentation: [Custom_Vision_Training_3.3](https://southcentralus.dev.cognitive.microsoft.com/docs/services/Custom_Vision_Training_3.3)\n",
    "- Azure SDK for Python: [Azure Cognitive Services Computer Vision SDK for Python](https://docs.microsoft.com/en-us/python/api/overview/azure/cognitiveservices-vision-computervision-readme?view=azure-python)\n",
    "- Source Code: [Azure/azure-sdk-for-python](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/cognitiveservices/azure-cognitiveservices-vision-customvision/azure/cognitiveservices/vision/customvision/training/operations/_custom_vision_training_client_operations.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91dff56",
   "metadata": {},
   "source": [
    "## Part 1.1: Create a Custom Vision Service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b05736",
   "metadata": {},
   "source": [
    "I'm not going to get into the details of creating the service. And the reason is that there is a detailed tutorial covering  not just that, but also the code for uploading and training a simple model. I encourage you to try it first:  \n",
    "[Detect Objects in Images with Custom Vision](https://microsoftlearning.github.io/AI-102-AIEngineer/Instructions/18-object-detection.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f17622",
   "metadata": {},
   "source": [
    "For this tutorial I created a Custom Vision with the following settings:\n",
    "\n",
    "Custom Vision service:\n",
    "- **Resource**: ai102cvision\n",
    "- **Resource Kind**: Custom Vision Training\n",
    "\n",
    "Project:\n",
    "- **Name**: Telecom Equipment Detection\n",
    "- **Description**: Detect different types of antennas\n",
    "- **Resource**: ai102cvision [F0]\n",
    "- **Project Types**: Object Detection\n",
    "- **Domains**: General\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d709e42",
   "metadata": {},
   "source": [
    "## Part 1.2: Upload the images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0195b56f",
   "metadata": {},
   "source": [
    "### Environment variables\n",
    "\n",
    "Update the configuration variables in the [.env](.env) file that contains:\n",
    "> ```\n",
    "TrainingEndpoint=YOUR_TRAINING_ENDPOINT\n",
    "TrainingKey=YOUR_TRAINING_KEY\n",
    "ProjectID=YOUR_PROJECT_ID\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038a4dc7",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "In order to protect my credentials, I'm going to store .env file in a `creds` folder that is not going to be pushed. \n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9809a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOTENV_PATH = './.env'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fe3b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "DOTENV_PATH = './creds/.env'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae63df3",
   "metadata": {},
   "source": [
    "### Install and Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8927ec",
   "metadata": {},
   "source": [
    "We need to install Custom Vision's Python SDK and python-dotenv:  \n",
    "`! pip install azure-cognitiveservices-vision-customvision==3.1.0`  \n",
    "`! pip install python-dotenv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b7bfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry, Region\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import UnidentifiedImageError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e066f4",
   "metadata": {},
   "source": [
    "### Credentials and Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e8a2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(DOTENV_PATH)\n",
    "training_endpoint = os.getenv('TrainingEndpoint')\n",
    "training_key = os.getenv('TrainingKey')\n",
    "project_id = os.getenv('ProjectID')\n",
    "\n",
    "credentials = ApiKeyCredentials(in_headers={\"Training-key\": training_key})\n",
    "training_client = CustomVisionTrainingClient(training_endpoint, credentials)\n",
    "custom_vision_project = training_client.get_project(project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b321a0f5",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955a4dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowed from fastai library\n",
    "def verify_image(fn):\n",
    "    \"Confirm that `fn` can be opened\"\n",
    "    try:\n",
    "        im = Image.open(fn)\n",
    "        im.draft(im.mode, (32,32))\n",
    "        im.load()\n",
    "        return True\n",
    "    except: return False\n",
    "    #except PIL.UnidentifiedImageError:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058cfbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Upload_Images_1by1(picture_names: list) -> list('dict'):\n",
    "    \"\"\"Upload the pictures from a list of paths,\n",
    "    one by one to keep track of the relation between\n",
    "    local image name and Azure image id.\n",
    "    And to track the ones that python fails opening\n",
    "    \"\"\"\n",
    "    print(\"Uploading images...\")\n",
    "\n",
    "    processed_ids = []\n",
    "    processed_status = []\n",
    "\n",
    "    for pic_name in picture_names:\n",
    "        pic_path = pictures_path / pic_name\n",
    "\n",
    "        if verify_image(pic_path):\n",
    "            with open(pic_path, mode=\"rb\") as image_data:\n",
    "                image_entry = ImageFileCreateEntry(name=pic_name, contents=image_data.read())\n",
    "            \n",
    "            # Upload the list of (1) images as a batch\n",
    "            upload_result = training_client.create_images_from_files(\n",
    "                custom_vision_project.id, \n",
    "                # Creates an ImageFileCreateBatch from a list of (1) ImageFileCreateEntry\n",
    "                ImageFileCreateBatch(images=[image_entry])\n",
    "            )\n",
    "            # Check for failure\n",
    "            if not upload_result.is_batch_successful:\n",
    "                pic_status = upload_result.images[0].status\n",
    "                pic_id = None\n",
    "            else:\n",
    "                pic_status = upload_result.images[0].status\n",
    "                pic_id = upload_result.images[0].image.id\n",
    "        else:\n",
    "            pic_status = \"ReadError\" # Equivalente to SDK `ErrorSource`\n",
    "            pic_id = None\n",
    "        \n",
    "        processed_status.append(pic_status)\n",
    "        processed_ids.append(pic_id)\n",
    "        print(pic_name, \"//\", pic_id, \"//\", pic_status)\n",
    "    \n",
    "    return [{\"image_name\": image_name, \"image_id\": image_id, \"image_status\": image_status} \n",
    "            for image_name, image_id, image_status in \n",
    "            zip(picture_names, processed_ids, processed_status)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314a3a77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4618a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
