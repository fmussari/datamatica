{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50da3568",
   "metadata": {},
   "source": [
    "---\n",
    "title: Telecom Equipment Detection with Azure Custom Vision (Free) - Part 3  \n",
    "author: \"Francisco Mussari\"  \n",
    "date: 2022-11-15  \n",
    "image: \"Part-2-Image.PNG\"  \n",
    "categories: [computer-vision, deeplearning, azure, custom-vision, object-detection, gradio]  \n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    toc-depth: 3\n",
    "    \n",
    "---\n",
    "\n",
    "Part 3. Deploy Gradio Web App"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bee1999",
   "metadata": {},
   "source": [
    "```python\n",
    "#|export\n",
    "import gradio as gr\n",
    "from fastcore.net import urljson, HTTPError\n",
    "```\n",
    "\n",
    "Next, write the functions your gradio app will use.  Because of [nbdev](https://nbdev.fast.ai/blog/posts/2022-07-28-nbdev2/), you can prototype and package your code all in one place.  **The special comment `#|export` marks which cells will be sent to a python script** (more on this later). Note that there are only three cells in this notebook with the `#|export` directive.\n",
    "\n",
    "\n",
    "```python\n",
    "#|export\n",
    "def size(repo:str):\n",
    "    \"Returns the size in GB of a HuggingFace Dataset.\"\n",
    "    url = f'https://huggingface.co/api/datasets/{repo}'\n",
    "    try: resp = urljson(f'{url}/treesize/main')\n",
    "    except HTTPError: return f'Did not find repo: {url}'\n",
    "    gb = resp['size'] / 1e9\n",
    "    return f'{gb:.2f} GB'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe690db",
   "metadata": {},
   "source": [
    "![](./blog-pictures/Part-2.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea1dcce",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e1a86b",
   "metadata": {},
   "source": [
    "After we train the model in Azure for 1 hour (free tier) and publishing it, when end up with a Prediction URL.\n",
    "\n",
    "![](./blog-pictures/Part-3-Iteration.PNG)\n",
    "\n",
    "We are going to use that Prediction endpoint to do the inference.\n",
    "\n",
    "Here is the App already published for you to try:  \n",
    "[Telecom-Object-Detection](https://huggingface.co/spaces/fmussari/Telecom-Object-Detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8606ed4f",
   "metadata": {},
   "source": [
    "#### The model was trained to detect the following objects:\n",
    "- Grid Antenna\n",
    "- Panel antenna\n",
    "- Radome antenna\n",
    "- RRU\n",
    "- Shroud antenna\n",
    "- Solid antenna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a58502",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td> <img src=\"blog-pictures/Grid.jpg\"  alt=\"1\" width = 200px height = 200px ></td>\n",
    "        <td><img src=\"blog-pictures/Panel.jpg\" alt=\"2\" width = 200px height = 200px></td>\n",
    "        <td><img src=\"blog-pictures/Radome.jpg\" alt=\"2\" width = 200px height = 200px></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Grid</td><td>Panel</td><td>Radome</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> <img src=\"blog-pictures/RRU.jpg\"  alt=\"1\" width = 200px height = 200px ></td>\n",
    "        <td> <img src=\"blog-pictures/Shroud.jpg\"  alt=\"1\" width = 200px height = 200px ></td>\n",
    "        <td> <img src=\"blog-pictures/Solid.jpg\"  alt=\"1\" width = 200px height = 200px ></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>RRU</td><td>Shroud</td><td>Solid</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7812f5e3",
   "metadata": {},
   "source": [
    "## Tutorial Parts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30ff1f4",
   "metadata": {},
   "source": [
    "- [Part 1](./ObjectDetectionWithAzureCustomVision_Part_1.ipynb) covered:\n",
    "    - Creating a [free](https://azure.microsoft.com/en-us/pricing/details/cognitive-services/custom-vision-service/#pricing) Azure [Custom Vision](https://www.customvision.ai/) Service.\n",
    "    - Uploading the images to the service.\n",
    "  \n",
    "- [Part 2](./ObjectDetectionWithAzureCustomVision_Part_2.ipynb) covered:\n",
    "    - Analyzing what happens to the images after uploading.\n",
    "    - How to label the images using [Smart Labeler](https://learn.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/suggested-tags)\n",
    "    - Training and testing the model.\n",
    "   \n",
    "- **Part 3**:\n",
    "    - Create a Huggingface Gradio Demo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2691db76",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Create A ðŸ¤— Space From A Notebook](https://nbdev.fast.ai/blog/posts/2022-11-07-spaces/)\n",
    "- [Build & Share Delightful Machine Learning Apps](https://gradio.app/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472512bb",
   "metadata": {},
   "source": [
    "## Part 3.1. Publishing a Gradio App"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad817222",
   "metadata": {},
   "source": [
    "Gradio is a great tool to demo machine learning models. The model is already deployed in Azure, so our Gradio App is going to be our front end to connect to that prediction endpoint. What I mean is that the model itself is not going to be deployed in Hugging Face Spaces, which is the normal workflow.\n",
    "\n",
    "If you are new to Gradio, I encourage you to start from the [Quickstart](https://gradio.app/getting_started/).\n",
    "\n",
    "The Gradio demo was created from a Jupyter Notebook with a great tool from [fast.ai](https://www.fast.ai/) which is [nbdev](https://nbdev.fast.ai/). You can start here: [Create A ðŸ¤— Space From A Notebook](https://nbdev.fast.ai/blog/posts/2022-11-07-spaces/)\n",
    "\n",
    "In both tutorials you will find the instructions to setup a Gradio enabled space in Hugging Face."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae63df3",
   "metadata": {},
   "source": [
    "### Install and import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8927ec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e9e215",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b7bfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "\n",
    "import requests, validators\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b321ffe",
   "metadata": {},
   "source": [
    "## Conslusions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ee87b6",
   "metadata": {},
   "source": [
    "- Object detection is a complex problem. The fact that the service does a reasonable good job with unbalanced training photos and with such a limited training time talks about the great margin for improvement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
