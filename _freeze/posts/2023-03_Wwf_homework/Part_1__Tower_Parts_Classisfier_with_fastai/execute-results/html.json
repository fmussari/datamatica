{
  "hash": "1095e3857d5e578d928c16772311b8ef",
  "result": {
    "markdown": "---\ntitle: Telecommunication towers component clasification - Part 1. fastai  \nauthor: \"Francisco Mussari\"  \ndate: 2023-03-06  \nimage: \"Part_1__fastai.PNG\"  \ncategories: [fastai, deeplearning, Walk with fastai, PyTorch]  \n\nexecute: \n  enabled: true\n  \nformat:\n  html:\n    toc: true\n    toc-depth: 3\n    \n---\n\n## Introduction\n\nThe first attempt for developing this idea started as the homework assignment for [lesson 1](https://course.fast.ai/videos/?lesson=1): Deep Learning 2019 (v3) [fast.ai](www.fast.ai) course. \n\nFor that homework I toke my domain expertise on telecommunication towers to build an image clasifier which could hopefuly recognize different tower components.\n\nIn may 2022 I was coursing live the 2022 version of the course, which is done in collaboration with [The University of Queensland](https://itee.uq.edu.au/event/2022/practical-deep-learning-coders-uq-fastai) and its now called [Practical Deep Learning for Coders](https://course.fast.ai/).  \n\nI'm running this notebook on an old GTX-1070 NVIDIA GPU.\n\n## Import Libraries\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom fastai.vision.all import *\nimport timm\nimport plotly.express as px\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/home/fmussari/mambaforge/envs/fastaiv3/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning:\n\nFailed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n\n```\n:::\n:::\n\n\n## Dataset\n\nI curated an image dataset of multiple towers I worked with in the past several years. And choosed 514 images in 8 relatively \"easy\" to distinguish categories (components). \n\nThe dataset was stored in google drive and is shared [here](https://drive.google.com/open?id=1Prtb9VbTau8Zk4c4K0YGFfL98MsGuf-F).\n\n### Local Dataset\n\nFor the 2022 course, thanks to the help of many great people in fastai forums, I was able to install fastai locally and to use my local GPU on WSL2.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\npath = Path(\"photos\")\n```\n:::\n\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ntrain_path = path / 'train'\nvalid_path = path / 'valid'\n\nlabels = [label.parts[-1] for label in train_path.iterdir()]\ntrain_quantity = [len(list(each.iterdir())) for each in train_path.iterdir()]\nvalid_quantity = [len(list(each.iterdir())) for each in valid_path.iterdir()]\ndf = pd.DataFrame()\n\ndf['label'] = labels * 2\ndf['set'] = ['train'] * 8 + ['valid'] * 8\ndf['quantity'] = train_quantity + valid_quantity\n```\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\ndf\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>set</th>\n      <th>quantity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>base_plate</td>\n      <td>train</td>\n      <td>87</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>grounding_bar</td>\n      <td>train</td>\n      <td>52</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>identification</td>\n      <td>train</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ladder</td>\n      <td>train</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>light</td>\n      <td>train</td>\n      <td>69</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>lightning_rod</td>\n      <td>train</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>platform</td>\n      <td>train</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>transmission_lines</td>\n      <td>train</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>base_plate</td>\n      <td>valid</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>grounding_bar</td>\n      <td>valid</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>identification</td>\n      <td>valid</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>ladder</td>\n      <td>valid</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>light</td>\n      <td>valid</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>lightning_rod</td>\n      <td>valid</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>platform</td>\n      <td>valid</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>transmission_lines</td>\n      <td>valid</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nis_train = df.set == 'train'\ndf[is_train].quantity.sum(), df[~is_train].quantity.sum()\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n(394, 120)\n```\n:::\n:::\n\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nfig = px.bar(\n    df, x=\"set\", y=\"quantity\",\n    color='label', barmode='group',\n    height=400\n)\nfig.show()\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<div>                            <div id=\"c8e46f13-8970-4f35-8c40-d21242ea72c0\" class=\"plotly-graph-div\" style=\"height:400px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c8e46f13-8970-4f35-8c40-d21242ea72c0\")) {                    Plotly.newPlot(                        \"c8e46f13-8970-4f35-8c40-d21242ea72c0\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"label=base_plate<br>set=%{x}<br>quantity=%{y}<extra></extra>\",\"legendgroup\":\"base_plate\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"base_plate\",\"offsetgroup\":\"base_plate\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"train\",\"valid\"],\"xaxis\":\"x\",\"y\":[87,29],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"label=grounding_bar<br>set=%{x}<br>quantity=%{y}<extra></extra>\",\"legendgroup\":\"grounding_bar\",\"marker\":{\"color\":\"#EF553B\",\"pattern\":{\"shape\":\"\"}},\"name\":\"grounding_bar\",\"offsetgroup\":\"grounding_bar\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"train\",\"valid\"],\"xaxis\":\"x\",\"y\":[52,15],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"label=identification<br>set=%{x}<br>quantity=%{y}<extra></extra>\",\"legendgroup\":\"identification\",\"marker\":{\"color\":\"#00cc96\",\"pattern\":{\"shape\":\"\"}},\"name\":\"identification\",\"offsetgroup\":\"identification\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"train\",\"valid\"],\"xaxis\":\"x\",\"y\":[30,8],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"label=ladder<br>set=%{x}<br>quantity=%{y}<extra></extra>\",\"legendgroup\":\"ladder\",\"marker\":{\"color\":\"#ab63fa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"ladder\",\"offsetgroup\":\"ladder\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"train\",\"valid\"],\"xaxis\":\"x\",\"y\":[37,11],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"label=light<br>set=%{x}<br>quantity=%{y}<extra></extra>\",\"legendgroup\":\"light\",\"marker\":{\"color\":\"#FFA15A\",\"pattern\":{\"shape\":\"\"}},\"name\":\"light\",\"offsetgroup\":\"light\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"train\",\"valid\"],\"xaxis\":\"x\",\"y\":[69,22],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"label=lightning_rod<br>set=%{x}<br>quantity=%{y}<extra></extra>\",\"legendgroup\":\"lightning_rod\",\"marker\":{\"color\":\"#19d3f3\",\"pattern\":{\"shape\":\"\"}},\"name\":\"lightning_rod\",\"offsetgroup\":\"lightning_rod\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"train\",\"valid\"],\"xaxis\":\"x\",\"y\":[33,10],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"label=platform<br>set=%{x}<br>quantity=%{y}<extra></extra>\",\"legendgroup\":\"platform\",\"marker\":{\"color\":\"#FF6692\",\"pattern\":{\"shape\":\"\"}},\"name\":\"platform\",\"offsetgroup\":\"platform\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"train\",\"valid\"],\"xaxis\":\"x\",\"y\":[57,16],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"label=transmission_lines<br>set=%{x}<br>quantity=%{y}<extra></extra>\",\"legendgroup\":\"transmission_lines\",\"marker\":{\"color\":\"#B6E880\",\"pattern\":{\"shape\":\"\"}},\"name\":\"transmission_lines\",\"offsetgroup\":\"transmission_lines\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"train\",\"valid\"],\"xaxis\":\"x\",\"y\":[29,9],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"set\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"quantity\"}},\"legend\":{\"title\":{\"text\":\"label\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"group\",\"height\":400},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('c8e46f13-8970-4f35-8c40-d21242ea72c0');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>\n```\n:::\n:::\n\n\n## The Data\n\nThe data was hand picked from a huge tower photoset. To start, I choose these eight easy distinguishable components to be clasified:  \n  \n\n- Base plate\n- Grounding bar\n- Identification\n- Ladder\n- Light\n- Lightning rod\n- Platform\n- Transmission lines\n\nThere are two folders, one for the training (train) and the other for the validation set (valid).\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nprint(path.ls())   \nprint('*'*100)\n(path/'train').ls()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[Path('photos/train'), Path('photos/valid')]\n****************************************************************************************************\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\n(#8) [Path('photos/train/base_plate'),Path('photos/train/grounding_bar'),Path('photos/train/identification'),Path('photos/train/ladder'),Path('photos/train/light'),Path('photos/train/lightning_rod'),Path('photos/train/platform'),Path('photos/train/transmission_lines')]\n```\n:::\n:::\n\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\ntower_parts_fns = get_image_files(path)\ntower_parts_fns\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\n(#514) [Path('photos/train/base_plate/Ac102-Corozopando-(64).jpg'),Path('photos/train/base_plate/Ac102-Corozopando-(75).jpg'),Path('photos/train/base_plate/camaguan-087.jpg'),Path('photos/train/base_plate/camaguan-098.jpg'),Path('photos/train/base_plate/cantv el yoco 015.JPG'),Path('photos/train/base_plate/cantv-capanaparo-011.jpg'),Path('photos/train/base_plate/cantv-cinaruco-018.jpg'),Path('photos/train/base_plate/cantv-cinaruco-025.jpg'),Path('photos/train/base_plate/cartanal-(7).jpg'),Path('photos/train/base_plate/CHUSPITA-II-AC-72-MTS-002.jpg')...]\n```\n:::\n:::\n\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nfailed = verify_images(tower_parts_fns)\nprint(failed)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[]\n```\n:::\n:::\n\n\n## DataLoaders\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\ntower_parts = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=GrandparentSplitter(train_name='train', valid_name='valid'),\n    get_y=parent_label,\n    item_tfms=Resize(224)\n)\n```\n:::\n\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\ndls = tower_parts.dataloaders(path)\n```\n:::\n\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\n%%time\nfor _ in dls.train: pass\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCPU times: user 178 ms, sys: 449 ms, total: 626 ms\nWall time: 25.5 s\n```\n:::\n:::\n\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\ndls.train.show_batch(max_n=16, nrows=4, figsize=(10,10))\n```\n\n::: {.cell-output .cell-output-display}\n![](Part_1__Tower_Parts_Classisfier_with_fastai_files/figure-html/cell-14-output-1.png){}\n:::\n:::\n\n\n## Learner\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nlearn = vision_learner(dls, resnet34, metrics=error_rate)\n```\n:::\n\n\n### fastai's `lr_find`\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\n%%time\nlearn.lr_find()\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nCPU times: user 27 s, sys: 9.19 s, total: 36.2 s\nWall time: 7min 12s\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=15}\n```\nSuggestedLRs(valley=0.0014454397605732083)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Part_1__Tower_Parts_Classisfier_with_fastai_files/figure-html/cell-16-output-5.png){}\n:::\n:::\n\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\ndls.num_workers\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\n1\n```\n:::\n:::\n\n\n::: {.callout-note}  \nI experimented by setting `dls.num_workers = 4` and it didn't make any difference in the time it takes to run `lr_find()`, even though that, by watching at the progress bar, it seemed that the bottleneck was in pre-processing the batch. Not in GPU.\n:::\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nlen(dls.train), len(dls.train.get_idxs())\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```\n(6, 394)\n```\n:::\n:::\n\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\nlen(dls.valid), len(dls.valid.get_idxs())\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```\n(2, 120)\n```\n:::\n:::\n\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\ndls.drop_last\n```\n\n::: {.cell-output .cell-output-display execution_count=19}\n```\nTrue\n```\n:::\n:::\n\n\n## Training\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\n%%time\nlearn.fine_tune(3)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>error_rate</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>2.751579</td>\n      <td>0.932106</td>\n      <td>0.316667</td>\n      <td>00:44</td>\n    </tr>\n  </tbody>\n</table>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>error_rate</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.000472</td>\n      <td>0.463910</td>\n      <td>0.166667</td>\n      <td>00:43</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.632878</td>\n      <td>0.272529</td>\n      <td>0.091667</td>\n      <td>00:43</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.429861</td>\n      <td>0.208375</td>\n      <td>0.050000</td>\n      <td>00:43</td>\n    </tr>\n  </tbody>\n</table>\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nCPU times: user 8.31 s, sys: 4.01 s, total: 12.3 s\nWall time: 2min 55s\n```\n:::\n:::\n\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix(figsize=(8,8))\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Part_1__Tower_Parts_Classisfier_with_fastai_files/figure-html/cell-22-output-5.png){}\n:::\n:::\n\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\ninterp.plot_top_losses(9)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Part_1__Tower_Parts_Classisfier_with_fastai_files/figure-html/cell-23-output-3.png){}\n:::\n:::\n\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\nlearn.export('models/tower_parts_model')\nlearn.save(\"exported_model_from_fastai\", with_opt=False)\n```\n\n::: {.cell-output .cell-output-display execution_count=23}\n```\nPath('models/exported_model_from_fastai.pth')\n```\n:::\n:::\n\n\n## Conclusions\n- I took about 500 pictures and 3 epochs to finetune a small pre-trained model to make it recognize 8 components with an error rate of about 6%.\n- `learn.lr_find()` took about 5 minutes to run, more that the fine tuning.\n- There are some categories that normally appear in one picture at the same time. I solved a classification problem to simplify, but maybe the actual problem should be a multi-class classificacion.\n\n",
    "supporting": [
      "Part_1__Tower_Parts_Classisfier_with_fastai_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        \n"
      ]
    }
  }
}